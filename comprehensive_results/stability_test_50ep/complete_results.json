{
  "experiment_name": "stability_test_50ep",
  "config": {
    "experiment_name": "stability_test_50ep",
    "learning_rate": 0.0005,
    "epsilon_decay": 0.9995,
    "memory_size": 50000,
    "batch_size": 128,
    "gamma": 0.98,
    "sequence_length": 10,
    "episodes": 50,
    "target_update_freq": 10,
    "save_freq": 25,
    "validation_freq": 15,
    "episode_duration": 300,
    "warmup_time": 30,
    "min_phase_time": 12,
    "max_phase_time": 120,
    "random_seed": 42,
    "validation_episodes": 10,
    "agent_type": "lstm",
    "offline_episodes": 35,
    "online_episodes": 15
  },
  "training_time_minutes": 236.01947324275972,
  "best_reward": -260.42286041742204,
  "convergence_episode": -1,
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -417.2075718484685,
      "steps": 300,
      "time_minutes": 2.7897018353144327,
      "avg_loss": 0.10900850910260233,
      "epsilon": 0.917574496577849,
      "vehicles": 356,
      "completed_trips": 490,
      "passenger_throughput": 8018.181818181819,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -330.31053012368574,
      "steps": 300,
      "time_minutes": 4.164105594158173,
      "avg_loss": 0.0617547074953715,
      "epsilon": 0.7897340627103864,
      "vehicles": 341,
      "completed_trips": 505,
      "passenger_throughput": 8263.636363636364,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -401.79877632539365,
      "steps": 300,
      "time_minutes": 4.208206478754679,
      "avg_loss": 0.04819875678668419,
      "epsilon": 0.6797049091175745,
      "vehicles": 365,
      "completed_trips": 540,
      "passenger_throughput": 8836.363636363638,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -317.18341574478666,
      "steps": 300,
      "time_minutes": 4.226705547173818,
      "avg_loss": 0.042131574352582295,
      "epsilon": 0.5850054914599224,
      "vehicles": 352,
      "completed_trips": 516,
      "passenger_throughput": 8443.636363636364,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -320.99671262462596,
      "steps": 300,
      "time_minutes": 4.237200633684794,
      "avg_loss": 0.03526157223929961,
      "epsilon": 0.5035000048514676,
      "vehicles": 313,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -356.99665919020566,
      "steps": 300,
      "time_minutes": 4.276333391666412,
      "avg_loss": 0.0322244304480652,
      "epsilon": 0.43335021394888135,
      "vehicles": 331,
      "completed_trips": 480,
      "passenger_throughput": 7854.545454545455,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -313.63246762895665,
      "steps": 300,
      "time_minutes": 4.304036017258962,
      "avg_loss": 0.029117244991163412,
      "epsilon": 0.37297399428017836,
      "vehicles": 358,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -397.40548273860963,
      "steps": 300,
      "time_minutes": 4.327144972483317,
      "avg_loss": 0.026599112258603175,
      "epsilon": 0.32100964977421276,
      "vehicles": 353,
      "completed_trips": 495,
      "passenger_throughput": 8100.000000000001,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -404.70777708622927,
      "steps": 300,
      "time_minutes": 4.357391719023386,
      "avg_loss": 0.02622652304979662,
      "epsilon": 0.27628520172576376,
      "vehicles": 354,
      "completed_trips": 478,
      "passenger_throughput": 7821.818181818182,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -313.95177378178835,
      "steps": 300,
      "time_minutes": 4.374318738778432,
      "avg_loss": 0.02554453625033299,
      "epsilon": 0.2377919565543782,
      "vehicles": 346,
      "completed_trips": 492,
      "passenger_throughput": 8050.909090909092,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -327.2248471866941,
      "steps": 300,
      "time_minutes": 4.4049143354098,
      "avg_loss": 0.06570272504041592,
      "epsilon": 0.20466175621698698,
      "vehicles": 363,
      "completed_trips": 513,
      "passenger_throughput": 8394.545454545456,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -390.11025558748366,
      "steps": 300,
      "time_minutes": 4.415912004311879,
      "avg_loss": 0.05750501733894149,
      "epsilon": 0.1761473981910859,
      "vehicles": 344,
      "completed_trips": 499,
      "passenger_throughput": 8165.454545454546,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -331.91254549218996,
      "steps": 300,
      "time_minutes": 4.401477018992106,
      "avg_loss": 0.0531120854926606,
      "epsilon": 0.15160578343025852,
      "vehicles": 308,
      "completed_trips": 447,
      "passenger_throughput": 7314.545454545455,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -412.53745799807507,
      "steps": 300,
      "time_minutes": 4.457914205392202,
      "avg_loss": 0.0521415495313704,
      "epsilon": 0.13048341221917423,
      "vehicles": 387,
      "completed_trips": 505,
      "passenger_throughput": 8263.636363636364,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -346.00377807624795,
      "steps": 300,
      "time_minutes": 4.4229648351669315,
      "avg_loss": 0.05008695056661963,
      "epsilon": 0.11230390080858102,
      "vehicles": 334,
      "completed_trips": 470,
      "passenger_throughput": 7690.909090909092,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -318.2869085321035,
      "steps": 300,
      "time_minutes": 4.379205624262492,
      "avg_loss": 0.05086731219043334,
      "epsilon": 0.09665723728652038,
      "vehicles": 312,
      "completed_trips": 473,
      "passenger_throughput": 7740.000000000001,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -423.3080618512041,
      "steps": 300,
      "time_minutes": 4.418512682120006,
      "avg_loss": 0.04655821692198515,
      "epsilon": 0.08319053436787543,
      "vehicles": 357,
      "completed_trips": 496,
      "passenger_throughput": 8116.363636363637,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -260.42286041742204,
      "steps": 300,
      "time_minutes": 4.408346597353617,
      "avg_loss": 0.04314780843754609,
      "epsilon": 0.07160007054513429,
      "vehicles": 319,
      "completed_trips": 528,
      "passenger_throughput": 8640.0,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -358.48490161287197,
      "steps": 300,
      "time_minutes": 4.424703598022461,
      "avg_loss": 0.041898553843299546,
      "epsilon": 0.0616244401003375,
      "vehicles": 354,
      "completed_trips": 507,
      "passenger_throughput": 8296.363636363638,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -425.3661852104741,
      "steps": 300,
      "time_minutes": 4.413446350892385,
      "avg_loss": 0.04136093247060974,
      "epsilon": 0.05303865748688375,
      "vehicles": 357,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 6000
    },
    {
      "episode": 21,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -427.23597839684174,
      "steps": 300,
      "time_minutes": 4.4219913204511005,
      "avg_loss": 0.08425436151524385,
      "epsilon": 0.045649083114274965,
      "vehicles": 330,
      "completed_trips": 466,
      "passenger_throughput": 7625.454545454546,
      "memory_size": 6300
    },
    {
      "episode": 22,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -343.5191312750031,
      "steps": 300,
      "time_minutes": 4.422844632466634,
      "avg_loss": 0.07775943464289109,
      "epsilon": 0.03928905609440261,
      "vehicles": 315,
      "completed_trips": 469,
      "passenger_throughput": 7674.545454545455,
      "memory_size": 6600
    },
    {
      "episode": 23,
      "scenario": "Day 20250716, Cycle 3",
      "reward": -386.35469115291943,
      "steps": 300,
      "time_minutes": 4.445439279079437,
      "avg_loss": 0.07629287652671338,
      "epsilon": 0.03381513545244477,
      "vehicles": 371,
      "completed_trips": 496,
      "passenger_throughput": 8116.363636363637,
      "memory_size": 6900
    },
    {
      "episode": 24,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -289.9587022622221,
      "steps": 300,
      "time_minutes": 4.420602770646413,
      "avg_loss": 0.0712075966099898,
      "epsilon": 0.029103865028462517,
      "vehicles": 309,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 7200
    },
    {
      "episode": 25,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -434.9850209169369,
      "steps": 300,
      "time_minutes": 4.442452649275462,
      "avg_loss": 0.06824454306314388,
      "epsilon": 0.02504898910685048,
      "vehicles": 349,
      "completed_trips": 492,
      "passenger_throughput": 8050.909090909092,
      "memory_size": 7500
    },
    {
      "episode": 26,
      "scenario": "Day 20250811, Cycle 3",
      "reward": -394.4577808316762,
      "steps": 300,
      "time_minutes": 4.472344819704691,
      "avg_loss": 0.06585114856561025,
      "epsilon": 0.021559055976293522,
      "vehicles": 365,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 7800
    },
    {
      "episode": 27,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -304.2608222513187,
      "steps": 300,
      "time_minutes": 4.463093872865041,
      "avg_loss": 0.06794712091485659,
      "epsilon": 0.01855535537207943,
      "vehicles": 317,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 8100
    },
    {
      "episode": 28,
      "scenario": "Day 20250812, Cycle 3",
      "reward": -418.73617864273405,
      "steps": 300,
      "time_minutes": 4.510920254389445,
      "avg_loss": 0.0648800695190827,
      "epsilon": 0.015970143282839144,
      "vehicles": 358,
      "completed_trips": 517,
      "passenger_throughput": 8460.0,
      "memory_size": 8400
    },
    {
      "episode": 29,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -385.5407235379696,
      "steps": 300,
      "time_minutes": 4.50216490427653,
      "avg_loss": 0.062336174386243025,
      "epsilon": 0.013745114084863256,
      "vehicles": 366,
      "completed_trips": 525,
      "passenger_throughput": 8590.909090909092,
      "memory_size": 8700
    },
    {
      "episode": 30,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -352.81903540311794,
      "steps": 300,
      "time_minutes": 4.486030908425649,
      "avg_loss": 0.05951264088352521,
      "epsilon": 0.011830085545251234,
      "vehicles": 310,
      "completed_trips": 484,
      "passenger_throughput": 7920.000000000001,
      "memory_size": 9000
    },
    {
      "episode": 31,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -364.2886231856565,
      "steps": 300,
      "time_minutes": 4.442321733633677,
      "avg_loss": 0.10238262730340163,
      "epsilon": 0.01018186703608976,
      "vehicles": 333,
      "completed_trips": 466,
      "passenger_throughput": 7625.454545454546,
      "memory_size": 9300
    },
    {
      "episode": 32,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -302.23800078568235,
      "steps": 300,
      "time_minutes": 4.443424570560455,
      "avg_loss": 0.09544698933760325,
      "epsilon": 0.009995187929535779,
      "vehicles": 347,
      "completed_trips": 478,
      "passenger_throughput": 7821.818181818182,
      "memory_size": 9600
    },
    {
      "episode": 33,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -337.1225914748949,
      "steps": 300,
      "time_minutes": 4.420101877053579,
      "avg_loss": 0.09377993680536748,
      "epsilon": 0.009995187929535779,
      "vehicles": 311,
      "completed_trips": 455,
      "passenger_throughput": 7445.454545454546,
      "memory_size": 9900
    },
    {
      "episode": 34,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -398.0160819863436,
      "steps": 300,
      "time_minutes": 4.487771860758463,
      "avg_loss": 0.08732367143034934,
      "epsilon": 0.009995187929535779,
      "vehicles": 363,
      "completed_trips": 510,
      "passenger_throughput": 8345.454545454546,
      "memory_size": 10200
    },
    {
      "episode": 35,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -345.41119596302207,
      "steps": 300,
      "time_minutes": 4.464093144734701,
      "avg_loss": 0.08330414281537135,
      "epsilon": 0.009995187929535779,
      "vehicles": 333,
      "completed_trips": 512,
      "passenger_throughput": 8378.181818181818,
      "memory_size": 10500
    },
    {
      "episode": 36,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -401.02539134747116,
      "steps": 300,
      "time_minutes": 4.248310160636902,
      "avg_loss": 0.08620104819536209,
      "epsilon": 0.009995187929535779,
      "vehicles": 365,
      "completed_trips": 519,
      "passenger_throughput": 8492.727272727274,
      "memory_size": 10800
    },
    {
      "episode": 37,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -401.2317428882637,
      "steps": 300,
      "time_minutes": 4.269490746657054,
      "avg_loss": 0.08312950193881989,
      "epsilon": 0.009995187929535779,
      "vehicles": 326,
      "completed_trips": 474,
      "passenger_throughput": 7756.363636363637,
      "memory_size": 11100
    },
    {
      "episode": 38,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -403.2341714585463,
      "steps": 300,
      "time_minutes": 4.27857863108317,
      "avg_loss": 0.07803191155195237,
      "epsilon": 0.009995187929535779,
      "vehicles": 394,
      "completed_trips": 498,
      "passenger_throughput": 8149.09090909091,
      "memory_size": 11400
    },
    {
      "episode": 39,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -375.1486871563684,
      "steps": 300,
      "time_minutes": 4.241923530896504,
      "avg_loss": 0.0722855091529588,
      "epsilon": 0.009995187929535779,
      "vehicles": 337,
      "completed_trips": 504,
      "passenger_throughput": 8247.272727272728,
      "memory_size": 11700
    },
    {
      "episode": 40,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -338.14377972639977,
      "steps": 300,
      "time_minutes": 4.258726076285044,
      "avg_loss": 0.07556731304774682,
      "epsilon": 0.009995187929535779,
      "vehicles": 342,
      "completed_trips": 514,
      "passenger_throughput": 8410.909090909092,
      "memory_size": 12000
    },
    {
      "episode": 41,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -368.19071319225066,
      "steps": 300,
      "time_minutes": 4.244262965520223,
      "avg_loss": 0.10900588937103749,
      "epsilon": 0.009995187929535779,
      "vehicles": 340,
      "completed_trips": 502,
      "passenger_throughput": 8214.545454545456,
      "memory_size": 12300
    },
    {
      "episode": 42,
      "scenario": "Day 20250709, Cycle 2",
      "reward": -409.82878414177475,
      "steps": 300,
      "time_minutes": 4.225959018866221,
      "avg_loss": 0.10932425564775865,
      "epsilon": 0.009995187929535779,
      "vehicles": 322,
      "completed_trips": 460,
      "passenger_throughput": 7527.272727272728,
      "memory_size": 12600
    },
    {
      "episode": 43,
      "scenario": "Day 20250708, Cycle 1",
      "reward": -396.478900768827,
      "steps": 300,
      "time_minutes": 4.246899060408274,
      "avg_loss": 0.10394851210216681,
      "epsilon": 0.009995187929535779,
      "vehicles": 322,
      "completed_trips": 473,
      "passenger_throughput": 7740.000000000001,
      "memory_size": 12900
    },
    {
      "episode": 44,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -354.10048844482964,
      "steps": 300,
      "time_minutes": 4.27143536011378,
      "avg_loss": 0.10551731836050748,
      "epsilon": 0.009995187929535779,
      "vehicles": 352,
      "completed_trips": 472,
      "passenger_throughput": 7723.636363636364,
      "memory_size": 13200
    },
    {
      "episode": 45,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -371.5640113379219,
      "steps": 300,
      "time_minutes": 4.26942732334137,
      "avg_loss": 0.09207904040813446,
      "epsilon": 0.009995187929535779,
      "vehicles": 365,
      "completed_trips": 483,
      "passenger_throughput": 7903.636363636364,
      "memory_size": 13500
    },
    {
      "episode": 46,
      "scenario": "Day 20250804, Cycle 1",
      "reward": -386.26802157304536,
      "steps": 300,
      "time_minutes": 4.283333110809326,
      "avg_loss": 0.09130170969913404,
      "epsilon": 0.009995187929535779,
      "vehicles": 350,
      "completed_trips": 479,
      "passenger_throughput": 7838.181818181819,
      "memory_size": 13800
    },
    {
      "episode": 47,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -382.5109241118318,
      "steps": 300,
      "time_minutes": 4.298646871248881,
      "avg_loss": 0.08916833924750488,
      "epsilon": 0.009995187929535779,
      "vehicles": 350,
      "completed_trips": 487,
      "passenger_throughput": 7969.09090909091,
      "memory_size": 14100
    },
    {
      "episode": 48,
      "scenario": "Day 20250807, Cycle 3",
      "reward": -394.656373740669,
      "steps": 300,
      "time_minutes": 4.327912557125091,
      "avg_loss": 0.09207620941102505,
      "epsilon": 0.009995187929535779,
      "vehicles": 352,
      "completed_trips": 480,
      "passenger_throughput": 7854.545454545455,
      "memory_size": 14400
    },
    {
      "episode": 49,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -404.0297682829543,
      "steps": 300,
      "time_minutes": 4.298629136880239,
      "avg_loss": 0.08863196925570567,
      "epsilon": 0.009995187929535779,
      "vehicles": 321,
      "completed_trips": 436,
      "passenger_throughput": 7134.545454545455,
      "memory_size": 14700
    },
    {
      "episode": 50,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -433.64205302760365,
      "steps": 300,
      "time_minutes": 4.326618603865305,
      "avg_loss": 0.09174718845635653,
      "epsilon": 0.009995187929535779,
      "vehicles": 357,
      "completed_trips": 473,
      "passenger_throughput": 7740.000000000001,
      "memory_size": 15000
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -403.53204052150903,
      "reward_std": 27.438742513819598,
      "avg_vehicles": 353.1,
      "avg_completed_trips": 481.1,
      "avg_passenger_throughput": 7872.545454545456,
      "scenarios_tested": 10
    },
    {
      "episode": 30,
      "avg_reward": -363.0167730096275,
      "reward_std": 41.88330269341835,
      "avg_vehicles": 355.8,
      "avg_completed_trips": 480.6,
      "avg_passenger_throughput": 7864.363636363638,
      "scenarios_tested": 10
    },
    {
      "episode": 45,
      "avg_reward": -382.6877482526223,
      "reward_std": 31.25434545779057,
      "avg_vehicles": 351.2,
      "avg_completed_trips": 483.4,
      "avg_passenger_throughput": 7910.181818181819,
      "scenarios_tested": 10
    }
  ],
  "final_evaluation": {
    "test_scenarios": 7,
    "comparison_results": null,
    "evaluation_timestamp": "2025-10-17T21:18:26.865090"
  },
  "logger_summary": {
    "experiment_id": "stability_test_50ep",
    "session_id": "712733d1-3dba-4531-b7f0-44477115e4f1",
    "timestamp": "2025-10-17T21:18:26.867143",
    "total_episodes": 50,
    "performance_metrics": {
      "avg_reward": -1.2315231558881745,
      "best_reward": -0.8680762013914068,
      "reward_improvement": -11.950237302352214,
      "avg_passenger_throughput": 7990.036363636364,
      "avg_vehicles_served": 488.28,
      "avg_pt_throughput": 2904.8
    },
    "learning_metrics": {
      "convergence_episode": -1,
      "stability_score": 0.8865170813888479,
      "exploration_rate": 1.227394504388616
    },
    "config": {
      "log_interval": 30,
      "buffer_size": 100,
      "total_steps": 14950
    }
  },
  "defense_ready": true,
  "timestamp": "2025-10-17T21:18:26.869134"
}