{
  "experiment_name": "extended_stabilization_test_30ep",
  "config": {
    "learning_rate": 0.0005,
    "epsilon_decay": 0.9995,
    "memory_size": 50000,
    "batch_size": 64,
    "gamma": 0.98,
    "sequence_length": 10,
    "episodes": 30,
    "target_update_freq": 10,
    "save_freq": 25,
    "validation_freq": 15,
    "episode_duration": 300,
    "warmup_time": 30,
    "min_phase_time": 12,
    "max_phase_time": 120,
    "random_seed": 42,
    "validation_episodes": 10,
    "agent_type": "lstm",
    "offline_episodes": 21,
    "online_episodes": 9
  },
  "training_time_minutes": 121.85287432273229,
  "best_reward": -249.29031138366742,
  "convergence_episode": -1,
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -376.0201645773619,
      "steps": 300,
      "time_minutes": 3.027822653452555,
      "avg_loss": 0.12039573006016219,
      "epsilon": 0.8886698277259029,
      "vehicles": 362,
      "completed_trips": 485,
      "passenger_throughput": 7936.363636363637,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -384.9840911832584,
      "steps": 300,
      "time_minutes": 3.613611368338267,
      "avg_loss": 0.07900419740006327,
      "epsilon": 0.764856516910148,
      "vehicles": 349,
      "completed_trips": 488,
      "passenger_throughput": 7985.454545454546,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -312.9881814435889,
      "steps": 300,
      "time_minutes": 3.6343265493710835,
      "avg_loss": 0.09373362068707744,
      "epsilon": 0.658293410227447,
      "vehicles": 370,
      "completed_trips": 526,
      "passenger_throughput": 8607.272727272728,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -288.06821963443224,
      "steps": 300,
      "time_minutes": 3.6503915866216023,
      "avg_loss": 0.07155554492026567,
      "epsilon": 0.5665771348847519,
      "vehicles": 346,
      "completed_trips": 515,
      "passenger_throughput": 8427.272727272728,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -293.19738083823484,
      "steps": 300,
      "time_minutes": 3.6613450050354004,
      "avg_loss": 0.056602675449103114,
      "epsilon": 0.4876391663457515,
      "vehicles": 314,
      "completed_trips": 465,
      "passenger_throughput": 7609.09090909091,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -397.72615208295633,
      "steps": 300,
      "time_minutes": 3.6633252064387003,
      "avg_loss": 0.044136739677439134,
      "epsilon": 0.4196991758284578,
      "vehicles": 342,
      "completed_trips": 492,
      "passenger_throughput": 8050.909090909092,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -393.7163429224055,
      "steps": 300,
      "time_minutes": 3.6692935983339945,
      "avg_loss": 0.039965679881473384,
      "epsilon": 0.3612248776305073,
      "vehicles": 365,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -353.12011542278486,
      "steps": 300,
      "time_minutes": 3.682062637805939,
      "avg_loss": 0.03728988485410809,
      "epsilon": 0.31089747069817225,
      "vehicles": 354,
      "completed_trips": 437,
      "passenger_throughput": 7150.909090909091,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -407.0874787978124,
      "steps": 300,
      "time_minutes": 3.705885922908783,
      "avg_loss": 0.03315400309860706,
      "epsilon": 0.2675818950249339,
      "vehicles": 348,
      "completed_trips": 479,
      "passenger_throughput": 7838.181818181819,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -353.4458054279013,
      "steps": 300,
      "time_minutes": 3.7163226207097373,
      "avg_loss": 0.031891832590724034,
      "epsilon": 0.23030123205680855,
      "vehicles": 352,
      "completed_trips": 495,
      "passenger_throughput": 8100.000000000001,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -428.0938162722531,
      "steps": 300,
      "time_minutes": 3.7429513414700826,
      "avg_loss": 0.07759881631781658,
      "epsilon": 0.19821467174354895,
      "vehicles": 373,
      "completed_trips": 507,
      "passenger_throughput": 8296.363636363638,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -412.4584958568504,
      "steps": 300,
      "time_minutes": 3.7991858959197997,
      "avg_loss": 0.06821011024216811,
      "epsilon": 0.17059854931523513,
      "vehicles": 363,
      "completed_trips": 479,
      "passenger_throughput": 7838.181818181819,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -362.71357013832267,
      "steps": 300,
      "time_minutes": 3.7247981985410052,
      "avg_loss": 0.0643025005608797,
      "epsilon": 0.14683002409689105,
      "vehicles": 303,
      "completed_trips": 452,
      "passenger_throughput": 7396.363636363637,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -382.3729694360515,
      "steps": 300,
      "time_minutes": 3.763472064336141,
      "avg_loss": 0.06304990804443757,
      "epsilon": 0.12637303226099805,
      "vehicles": 388,
      "completed_trips": 517,
      "passenger_throughput": 8460.0,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -413.0784738956223,
      "steps": 300,
      "time_minutes": 3.7419821500778196,
      "avg_loss": 0.05942141758898894,
      "epsilon": 0.1087661967030719,
      "vehicles": 333,
      "completed_trips": 460,
      "passenger_throughput": 7527.272727272728,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -358.4864866025355,
      "steps": 300,
      "time_minutes": 3.7344855666160583,
      "avg_loss": 0.05342820777247349,
      "epsilon": 0.09361242136549094,
      "vehicles": 301,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -382.3200056012395,
      "steps": 300,
      "time_minutes": 3.7610838294029234,
      "avg_loss": 0.05138839974378546,
      "epsilon": 0.08056993532497697,
      "vehicles": 355,
      "completed_trips": 490,
      "passenger_throughput": 8018.181818181819,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -249.29031138366742,
      "steps": 300,
      "time_minutes": 3.7545243382453917,
      "avg_loss": 0.05149070229381323,
      "epsilon": 0.0693445846564117,
      "vehicles": 320,
      "completed_trips": 516,
      "passenger_throughput": 8443.636363636364,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -416.9836160825312,
      "steps": 300,
      "time_minutes": 3.7911611795425415,
      "avg_loss": 0.05101064390813311,
      "epsilon": 0.059683198227410465,
      "vehicles": 372,
      "completed_trips": 498,
      "passenger_throughput": 8149.09090909091,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -383.00458884167233,
      "steps": 300,
      "time_minutes": 3.749546464284261,
      "avg_loss": 0.05072325199842453,
      "epsilon": 0.05136787779899155,
      "vehicles": 352,
      "completed_trips": 483,
      "passenger_throughput": 7903.636363636364,
      "memory_size": 6000
    },
    {
      "episode": 21,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -388.1469018929072,
      "steps": 300,
      "time_minutes": 3.747110692660014,
      "avg_loss": 0.10099374243368706,
      "epsilon": 0.04421108365403042,
      "vehicles": 334,
      "completed_trips": 462,
      "passenger_throughput": 7560.000000000001,
      "memory_size": 6300
    },
    {
      "episode": 22,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -324.12411539069217,
      "steps": 300,
      "time_minutes": 3.740234013398488,
      "avg_loss": 0.08441546039034922,
      "epsilon": 0.04163618072554449,
      "vehicles": 323,
      "completed_trips": 464,
      "passenger_throughput": 7592.727272727273,
      "memory_size": 6600
    },
    {
      "episode": 23,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -323.60756254992424,
      "steps": 300,
      "time_minutes": 3.7533293922742206,
      "avg_loss": 0.08795720441887776,
      "epsilon": 0.039211243021684286,
      "vehicles": 322,
      "completed_trips": 483,
      "passenger_throughput": 7903.636363636364,
      "memory_size": 6900
    },
    {
      "episode": 24,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -405.74163694746835,
      "steps": 300,
      "time_minutes": 3.7902518351872763,
      "avg_loss": 0.07835400201380253,
      "epsilon": 0.03692753640014567,
      "vehicles": 375,
      "completed_trips": 525,
      "passenger_throughput": 8590.909090909092,
      "memory_size": 7200
    },
    {
      "episode": 25,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -378.15256207550624,
      "steps": 300,
      "time_minutes": 3.7768511970837912,
      "avg_loss": 0.07698853698869547,
      "epsilon": 0.03477683540483463,
      "vehicles": 339,
      "completed_trips": 504,
      "passenger_throughput": 8247.272727272728,
      "memory_size": 7500
    },
    {
      "episode": 26,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -405.875666284201,
      "steps": 300,
      "time_minutes": 3.844399853547414,
      "avg_loss": 0.07081926287462315,
      "epsilon": 0.03275139363941393,
      "vehicles": 346,
      "completed_trips": 509,
      "passenger_throughput": 8329.09090909091,
      "memory_size": 7800
    },
    {
      "episode": 27,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -342.96911362797255,
      "steps": 300,
      "time_minutes": 3.787798329194387,
      "avg_loss": 0.07128008379290501,
      "epsilon": 0.030843915866327638,
      "vehicles": 336,
      "completed_trips": 490,
      "passenger_throughput": 8018.181818181819,
      "memory_size": 8100
    },
    {
      "episode": 28,
      "scenario": "Day 20250709, Cycle 2",
      "reward": -360.0871248514766,
      "steps": 300,
      "time_minutes": 3.774531038602193,
      "avg_loss": 0.06821928646415472,
      "epsilon": 0.029047531730809168,
      "vehicles": 321,
      "completed_trips": 454,
      "passenger_throughput": 7429.09090909091,
      "memory_size": 8400
    },
    {
      "episode": 29,
      "scenario": "Day 20250708, Cycle 1",
      "reward": -294.6683717182374,
      "steps": 300,
      "time_minutes": 3.767231039206187,
      "avg_loss": 0.06561437573904792,
      "epsilon": 0.027355771015232812,
      "vehicles": 302,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 8700
    },
    {
      "episode": 30,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -320.57882510594186,
      "steps": 300,
      "time_minutes": 3.792262156804403,
      "avg_loss": 0.06284261974816521,
      "epsilon": 0.02576254033467945,
      "vehicles": 354,
      "completed_trips": 484,
      "passenger_throughput": 7920.000000000001,
      "memory_size": 9000
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -372.5356342674261,
      "reward_std": 42.77944635833511,
      "avg_vehicles": 354.6,
      "avg_completed_trips": 480.8,
      "avg_passenger_throughput": 7867.636363636363,
      "scenarios_tested": 10
    },
    {
      "episode": 30,
      "avg_reward": -381.12898231735187,
      "reward_std": 43.63832597053473,
      "avg_vehicles": 351.6,
      "avg_completed_trips": 481.4,
      "avg_passenger_throughput": 7877.454545454546,
      "scenarios_tested": 10
    }
  ],
  "final_evaluation": {
    "test_scenarios": 7,
    "comparison_results": null,
    "evaluation_timestamp": "2025-10-16T12:38:05.048124"
  },
  "logger_summary": {
    "experiment_id": "extended_stabilization_test_30ep",
    "session_id": "bfaf7add-e599-48d4-9b1d-210a9d8197ac",
    "timestamp": "2025-10-16T12:38:05.050122",
    "total_episodes": 30,
    "performance_metrics": {
      "avg_reward": -1.210345349653979,
      "best_reward": -0.8309677046122246,
      "reward_improvement": -4.163765548462922,
      "avg_passenger_throughput": 7963.636363636366,
      "avg_vehicles_served": 486.6666666666667,
      "avg_pt_throughput": 0.0
    },
    "learning_metrics": {
      "convergence_episode": -1,
      "stability_score": 0.8782852373866757,
      "exploration_rate": 1.088297499465808
    },
    "config": {
      "log_interval": 30,
      "buffer_size": 100,
      "total_steps": 8970
    }
  },
  "defense_ready": true,
  "timestamp": "2025-10-16T12:38:05.051116"
}