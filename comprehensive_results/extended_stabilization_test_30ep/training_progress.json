{
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -376.0201645773619,
      "steps": 300,
      "time_minutes": 3.027822653452555,
      "avg_loss": 0.12039573006016219,
      "epsilon": 0.8886698277259029,
      "vehicles": 362,
      "completed_trips": 485,
      "passenger_throughput": 7936.363636363637,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -384.9840911832584,
      "steps": 300,
      "time_minutes": 3.613611368338267,
      "avg_loss": 0.07900419740006327,
      "epsilon": 0.764856516910148,
      "vehicles": 349,
      "completed_trips": 488,
      "passenger_throughput": 7985.454545454546,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -312.9881814435889,
      "steps": 300,
      "time_minutes": 3.6343265493710835,
      "avg_loss": 0.09373362068707744,
      "epsilon": 0.658293410227447,
      "vehicles": 370,
      "completed_trips": 526,
      "passenger_throughput": 8607.272727272728,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -288.06821963443224,
      "steps": 300,
      "time_minutes": 3.6503915866216023,
      "avg_loss": 0.07155554492026567,
      "epsilon": 0.5665771348847519,
      "vehicles": 346,
      "completed_trips": 515,
      "passenger_throughput": 8427.272727272728,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -293.19738083823484,
      "steps": 300,
      "time_minutes": 3.6613450050354004,
      "avg_loss": 0.056602675449103114,
      "epsilon": 0.4876391663457515,
      "vehicles": 314,
      "completed_trips": 465,
      "passenger_throughput": 7609.09090909091,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -397.72615208295633,
      "steps": 300,
      "time_minutes": 3.6633252064387003,
      "avg_loss": 0.044136739677439134,
      "epsilon": 0.4196991758284578,
      "vehicles": 342,
      "completed_trips": 492,
      "passenger_throughput": 8050.909090909092,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -393.7163429224055,
      "steps": 300,
      "time_minutes": 3.6692935983339945,
      "avg_loss": 0.039965679881473384,
      "epsilon": 0.3612248776305073,
      "vehicles": 365,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -353.12011542278486,
      "steps": 300,
      "time_minutes": 3.682062637805939,
      "avg_loss": 0.03728988485410809,
      "epsilon": 0.31089747069817225,
      "vehicles": 354,
      "completed_trips": 437,
      "passenger_throughput": 7150.909090909091,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -407.0874787978124,
      "steps": 300,
      "time_minutes": 3.705885922908783,
      "avg_loss": 0.03315400309860706,
      "epsilon": 0.2675818950249339,
      "vehicles": 348,
      "completed_trips": 479,
      "passenger_throughput": 7838.181818181819,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -353.4458054279013,
      "steps": 300,
      "time_minutes": 3.7163226207097373,
      "avg_loss": 0.031891832590724034,
      "epsilon": 0.23030123205680855,
      "vehicles": 352,
      "completed_trips": 495,
      "passenger_throughput": 8100.000000000001,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -428.0938162722531,
      "steps": 300,
      "time_minutes": 3.7429513414700826,
      "avg_loss": 0.07759881631781658,
      "epsilon": 0.19821467174354895,
      "vehicles": 373,
      "completed_trips": 507,
      "passenger_throughput": 8296.363636363638,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -412.4584958568504,
      "steps": 300,
      "time_minutes": 3.7991858959197997,
      "avg_loss": 0.06821011024216811,
      "epsilon": 0.17059854931523513,
      "vehicles": 363,
      "completed_trips": 479,
      "passenger_throughput": 7838.181818181819,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -362.71357013832267,
      "steps": 300,
      "time_minutes": 3.7247981985410052,
      "avg_loss": 0.0643025005608797,
      "epsilon": 0.14683002409689105,
      "vehicles": 303,
      "completed_trips": 452,
      "passenger_throughput": 7396.363636363637,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -382.3729694360515,
      "steps": 300,
      "time_minutes": 3.763472064336141,
      "avg_loss": 0.06304990804443757,
      "epsilon": 0.12637303226099805,
      "vehicles": 388,
      "completed_trips": 517,
      "passenger_throughput": 8460.0,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -413.0784738956223,
      "steps": 300,
      "time_minutes": 3.7419821500778196,
      "avg_loss": 0.05942141758898894,
      "epsilon": 0.1087661967030719,
      "vehicles": 333,
      "completed_trips": 460,
      "passenger_throughput": 7527.272727272728,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -358.4864866025355,
      "steps": 300,
      "time_minutes": 3.7344855666160583,
      "avg_loss": 0.05342820777247349,
      "epsilon": 0.09361242136549094,
      "vehicles": 301,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -382.3200056012395,
      "steps": 300,
      "time_minutes": 3.7610838294029234,
      "avg_loss": 0.05138839974378546,
      "epsilon": 0.08056993532497697,
      "vehicles": 355,
      "completed_trips": 490,
      "passenger_throughput": 8018.181818181819,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -249.29031138366742,
      "steps": 300,
      "time_minutes": 3.7545243382453917,
      "avg_loss": 0.05149070229381323,
      "epsilon": 0.0693445846564117,
      "vehicles": 320,
      "completed_trips": 516,
      "passenger_throughput": 8443.636363636364,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -416.9836160825312,
      "steps": 300,
      "time_minutes": 3.7911611795425415,
      "avg_loss": 0.05101064390813311,
      "epsilon": 0.059683198227410465,
      "vehicles": 372,
      "completed_trips": 498,
      "passenger_throughput": 8149.09090909091,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -383.00458884167233,
      "steps": 300,
      "time_minutes": 3.749546464284261,
      "avg_loss": 0.05072325199842453,
      "epsilon": 0.05136787779899155,
      "vehicles": 352,
      "completed_trips": 483,
      "passenger_throughput": 7903.636363636364,
      "memory_size": 6000
    },
    {
      "episode": 21,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -388.1469018929072,
      "steps": 300,
      "time_minutes": 3.747110692660014,
      "avg_loss": 0.10099374243368706,
      "epsilon": 0.04421108365403042,
      "vehicles": 334,
      "completed_trips": 462,
      "passenger_throughput": 7560.000000000001,
      "memory_size": 6300
    },
    {
      "episode": 22,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -324.12411539069217,
      "steps": 300,
      "time_minutes": 3.740234013398488,
      "avg_loss": 0.08441546039034922,
      "epsilon": 0.04163618072554449,
      "vehicles": 323,
      "completed_trips": 464,
      "passenger_throughput": 7592.727272727273,
      "memory_size": 6600
    },
    {
      "episode": 23,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -323.60756254992424,
      "steps": 300,
      "time_minutes": 3.7533293922742206,
      "avg_loss": 0.08795720441887776,
      "epsilon": 0.039211243021684286,
      "vehicles": 322,
      "completed_trips": 483,
      "passenger_throughput": 7903.636363636364,
      "memory_size": 6900
    },
    {
      "episode": 24,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -405.74163694746835,
      "steps": 300,
      "time_minutes": 3.7902518351872763,
      "avg_loss": 0.07835400201380253,
      "epsilon": 0.03692753640014567,
      "vehicles": 375,
      "completed_trips": 525,
      "passenger_throughput": 8590.909090909092,
      "memory_size": 7200
    },
    {
      "episode": 25,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -378.15256207550624,
      "steps": 300,
      "time_minutes": 3.7768511970837912,
      "avg_loss": 0.07698853698869547,
      "epsilon": 0.03477683540483463,
      "vehicles": 339,
      "completed_trips": 504,
      "passenger_throughput": 8247.272727272728,
      "memory_size": 7500
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -372.5356342674261,
      "reward_std": 42.77944635833511,
      "avg_vehicles": 354.6,
      "avg_completed_trips": 480.8,
      "avg_passenger_throughput": 7867.636363636363,
      "scenarios_tested": 10
    }
  ],
  "last_updated": "2025-10-16T12:08:47.500257"
}