{
  "experiment_name": "verification_100ep_batch64",
  "config": {
    "experiment_name": "verification_100ep_batch64",
    "learning_rate": 0.0005,
    "epsilon_decay": 0.9995,
    "memory_size": 50000,
    "batch_size": 128,
    "gamma": 0.98,
    "sequence_length": 10,
    "episodes": 100,
    "target_update_freq": 10,
    "save_freq": 25,
    "validation_freq": 15,
    "episode_duration": 300,
    "warmup_time": 30,
    "min_phase_time": 12,
    "max_phase_time": 120,
    "random_seed": 42,
    "validation_episodes": 10,
    "agent_type": "lstm",
    "offline_episodes": 70,
    "online_episodes": 30
  },
  "training_time_minutes": 436.74099057912827,
  "best_reward": -221.21327120217302,
  "convergence_episode": -1,
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -376.201559254467,
      "steps": 300,
      "time_minutes": 2.595982587337494,
      "avg_loss": 0.10364507558907188,
      "epsilon": 0.917574496577849,
      "vehicles": 348,
      "completed_trips": 491,
      "passenger_throughput": 8034.545454545455,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -410.3512252878996,
      "steps": 300,
      "time_minutes": 3.8871419548988344,
      "avg_loss": 0.06376866579055786,
      "epsilon": 0.7897340627103864,
      "vehicles": 348,
      "completed_trips": 491,
      "passenger_throughput": 8034.545454545455,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -335.60662482846845,
      "steps": 300,
      "time_minutes": 4.084667932987213,
      "avg_loss": 0.05199984040111303,
      "epsilon": 0.6797049091175745,
      "vehicles": 363,
      "completed_trips": 528,
      "passenger_throughput": 8640.0,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -328.43860424161795,
      "steps": 300,
      "time_minutes": 3.8999327341715495,
      "avg_loss": 0.043924799791226786,
      "epsilon": 0.5850054914599224,
      "vehicles": 347,
      "completed_trips": 518,
      "passenger_throughput": 8476.363636363638,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -359.8162390336478,
      "steps": 300,
      "time_minutes": 3.919287137190501,
      "avg_loss": 0.038276601104686656,
      "epsilon": 0.5035000048514676,
      "vehicles": 298,
      "completed_trips": 485,
      "passenger_throughput": 7936.363636363637,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -378.7157522298807,
      "steps": 300,
      "time_minutes": 3.945185379187266,
      "avg_loss": 0.037714903745800256,
      "epsilon": 0.43335021394888135,
      "vehicles": 343,
      "completed_trips": 490,
      "passenger_throughput": 8018.181818181819,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -371.0027398930917,
      "steps": 300,
      "time_minutes": 3.9622172435124714,
      "avg_loss": 0.0334537334057192,
      "epsilon": 0.37297399428017836,
      "vehicles": 361,
      "completed_trips": 436,
      "passenger_throughput": 7134.545454545455,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -312.0709911615926,
      "steps": 300,
      "time_minutes": 3.977735451857249,
      "avg_loss": 0.032962368701895076,
      "epsilon": 0.32100964977421276,
      "vehicles": 360,
      "completed_trips": 478,
      "passenger_throughput": 7821.818181818182,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -403.89317504825516,
      "steps": 300,
      "time_minutes": 3.9921624938646953,
      "avg_loss": 0.029771888672063748,
      "epsilon": 0.27628520172576376,
      "vehicles": 344,
      "completed_trips": 498,
      "passenger_throughput": 8149.09090909091,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -342.8131212796291,
      "steps": 300,
      "time_minutes": 4.012480247020721,
      "avg_loss": 0.029132807940865556,
      "epsilon": 0.2377919565543782,
      "vehicles": 354,
      "completed_trips": 503,
      "passenger_throughput": 8230.909090909092,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -388.00265055076903,
      "steps": 300,
      "time_minutes": 4.041326038042704,
      "avg_loss": 0.06650844893107812,
      "epsilon": 0.20466175621698698,
      "vehicles": 384,
      "completed_trips": 494,
      "passenger_throughput": 8083.636363636364,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -362.40154952383807,
      "steps": 300,
      "time_minutes": 4.041376479466757,
      "avg_loss": 0.05673038435479005,
      "epsilon": 0.1761473981910859,
      "vehicles": 353,
      "completed_trips": 486,
      "passenger_throughput": 7952.727272727273,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -364.7828439982334,
      "steps": 300,
      "time_minutes": 4.030649248758952,
      "avg_loss": 0.050385650787502526,
      "epsilon": 0.15160578343025852,
      "vehicles": 310,
      "completed_trips": 449,
      "passenger_throughput": 7347.272727272728,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -452.6446195556938,
      "steps": 300,
      "time_minutes": 4.095720112323761,
      "avg_loss": 0.04765150183811784,
      "epsilon": 0.13048341221917423,
      "vehicles": 407,
      "completed_trips": 502,
      "passenger_throughput": 8214.545454545456,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -242.7586602415758,
      "steps": 300,
      "time_minutes": 4.057997405529022,
      "avg_loss": 0.045938028519352275,
      "epsilon": 0.11230390080858102,
      "vehicles": 328,
      "completed_trips": 466,
      "passenger_throughput": 7625.454545454546,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -388.38715252237586,
      "steps": 300,
      "time_minutes": 4.0591497341791785,
      "avg_loss": 0.044336189460009334,
      "epsilon": 0.09665723728652038,
      "vehicles": 322,
      "completed_trips": 480,
      "passenger_throughput": 7854.545454545455,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -367.9695894197586,
      "steps": 300,
      "time_minutes": 4.070378331343333,
      "avg_loss": 0.0428648234407107,
      "epsilon": 0.08319053436787543,
      "vehicles": 348,
      "completed_trips": 493,
      "passenger_throughput": 8067.272727272728,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -340.1543959509626,
      "steps": 300,
      "time_minutes": 4.057806694507599,
      "avg_loss": 0.040936104928453766,
      "epsilon": 0.07160007054513429,
      "vehicles": 328,
      "completed_trips": 499,
      "passenger_throughput": 8165.454545454546,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -286.63680560024284,
      "steps": 300,
      "time_minutes": 4.071129997571309,
      "avg_loss": 0.039074222420652706,
      "epsilon": 0.0616244401003375,
      "vehicles": 356,
      "completed_trips": 510,
      "passenger_throughput": 8345.454545454546,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -365.91657217399234,
      "steps": 300,
      "time_minutes": 4.077700897057851,
      "avg_loss": 0.03684545212114851,
      "epsilon": 0.05303865748688375,
      "vehicles": 354,
      "completed_trips": 466,
      "passenger_throughput": 7625.454545454546,
      "memory_size": 6000
    },
    {
      "episode": 21,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -360.6095490248632,
      "steps": 300,
      "time_minutes": 4.069601837793986,
      "avg_loss": 0.07600213589767615,
      "epsilon": 0.045649083114274965,
      "vehicles": 336,
      "completed_trips": 449,
      "passenger_throughput": 7347.272727272728,
      "memory_size": 6300
    },
    {
      "episode": 22,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -314.5749668400769,
      "steps": 300,
      "time_minutes": 4.067375536759695,
      "avg_loss": 0.06724581160893042,
      "epsilon": 0.03928905609440261,
      "vehicles": 324,
      "completed_trips": 461,
      "passenger_throughput": 7543.636363636364,
      "memory_size": 6600
    },
    {
      "episode": 23,
      "scenario": "Day 20250716, Cycle 3",
      "reward": -335.73253314318634,
      "steps": 300,
      "time_minutes": 4.087245309352875,
      "avg_loss": 0.061163508867224055,
      "epsilon": 0.03381513545244477,
      "vehicles": 359,
      "completed_trips": 528,
      "passenger_throughput": 8640.0,
      "memory_size": 6900
    },
    {
      "episode": 24,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -337.9124292294673,
      "steps": 300,
      "time_minutes": 4.062445640563965,
      "avg_loss": 0.06048530160139005,
      "epsilon": 0.029103865028462517,
      "vehicles": 305,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 7200
    },
    {
      "episode": 25,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -368.6946837162681,
      "steps": 300,
      "time_minutes": 4.0749414165814715,
      "avg_loss": 0.05850924084583918,
      "epsilon": 0.02504898910685048,
      "vehicles": 344,
      "completed_trips": 502,
      "passenger_throughput": 8214.545454545456,
      "memory_size": 7500
    },
    {
      "episode": 26,
      "scenario": "Day 20250811, Cycle 3",
      "reward": -437.5402535024081,
      "steps": 300,
      "time_minutes": 4.0870283087094625,
      "avg_loss": 0.055017230523129304,
      "epsilon": 0.021559055976293522,
      "vehicles": 367,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 7800
    },
    {
      "episode": 27,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -332.2376066493456,
      "steps": 300,
      "time_minutes": 4.064576192696889,
      "avg_loss": 0.05684125106781721,
      "epsilon": 0.01855535537207943,
      "vehicles": 299,
      "completed_trips": 485,
      "passenger_throughput": 7936.363636363637,
      "memory_size": 8100
    },
    {
      "episode": 28,
      "scenario": "Day 20250812, Cycle 3",
      "reward": -338.23259665222577,
      "steps": 300,
      "time_minutes": 4.0980404694875086,
      "avg_loss": 0.05429651953279972,
      "epsilon": 0.015970143282839144,
      "vehicles": 355,
      "completed_trips": 518,
      "passenger_throughput": 8476.363636363638,
      "memory_size": 8400
    },
    {
      "episode": 29,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -381.3206410569617,
      "steps": 300,
      "time_minutes": 4.098513464132945,
      "avg_loss": 0.052944779321551325,
      "epsilon": 0.013745114084863256,
      "vehicles": 373,
      "completed_trips": 510,
      "passenger_throughput": 8345.454545454546,
      "memory_size": 8700
    },
    {
      "episode": 30,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -314.7971298833469,
      "steps": 300,
      "time_minutes": 4.067254288991292,
      "avg_loss": 0.050423561229060096,
      "epsilon": 0.011830085545251234,
      "vehicles": 302,
      "completed_trips": 483,
      "passenger_throughput": 7903.636363636364,
      "memory_size": 9000
    },
    {
      "episode": 31,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -390.93652538017017,
      "steps": 300,
      "time_minutes": 4.05870787302653,
      "avg_loss": 0.0889450250317653,
      "epsilon": 0.01018186703608976,
      "vehicles": 339,
      "completed_trips": 463,
      "passenger_throughput": 7576.363636363637,
      "memory_size": 9300
    },
    {
      "episode": 32,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -364.225783269034,
      "steps": 300,
      "time_minutes": 4.076141162713369,
      "avg_loss": 0.08101965084671975,
      "epsilon": 0.009995187929535779,
      "vehicles": 337,
      "completed_trips": 480,
      "passenger_throughput": 7854.545454545455,
      "memory_size": 9600
    },
    {
      "episode": 33,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -345.4771882761936,
      "steps": 300,
      "time_minutes": 4.06168870528539,
      "avg_loss": 0.08153149299323559,
      "epsilon": 0.009995187929535779,
      "vehicles": 316,
      "completed_trips": 448,
      "passenger_throughput": 7330.909090909091,
      "memory_size": 9900
    },
    {
      "episode": 34,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -423.1977439390816,
      "steps": 300,
      "time_minutes": 4.101165775458018,
      "avg_loss": 0.07360703037430842,
      "epsilon": 0.009995187929535779,
      "vehicles": 372,
      "completed_trips": 506,
      "passenger_throughput": 8280.0,
      "memory_size": 10200
    },
    {
      "episode": 35,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -393.6099006533743,
      "steps": 300,
      "time_minutes": 4.07088905175527,
      "avg_loss": 0.07701541749139627,
      "epsilon": 0.009995187929535779,
      "vehicles": 338,
      "completed_trips": 501,
      "passenger_throughput": 8198.181818181818,
      "memory_size": 10500
    },
    {
      "episode": 36,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -381.48510940796103,
      "steps": 300,
      "time_minutes": 4.088115378220876,
      "avg_loss": 0.0722086584319671,
      "epsilon": 0.009995187929535779,
      "vehicles": 379,
      "completed_trips": 493,
      "passenger_throughput": 8067.272727272728,
      "memory_size": 10800
    },
    {
      "episode": 37,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -387.1144188114114,
      "steps": 300,
      "time_minutes": 4.056460126241048,
      "avg_loss": 0.07296370436747869,
      "epsilon": 0.009995187929535779,
      "vehicles": 320,
      "completed_trips": 452,
      "passenger_throughput": 7396.363636363637,
      "memory_size": 11100
    },
    {
      "episode": 38,
      "scenario": "Day 20250818, Cycle 2",
      "reward": -422.5809418698872,
      "steps": 300,
      "time_minutes": 4.0734883109728495,
      "avg_loss": 0.07442884945621094,
      "epsilon": 0.009995187929535779,
      "vehicles": 336,
      "completed_trips": 469,
      "passenger_throughput": 7674.545454545455,
      "memory_size": 11400
    },
    {
      "episode": 39,
      "scenario": "Day 20250805, Cycle 1",
      "reward": -421.4363721262857,
      "steps": 300,
      "time_minutes": 4.091400162378947,
      "avg_loss": 0.06989299955467383,
      "epsilon": 0.009995187929535779,
      "vehicles": 374,
      "completed_trips": 439,
      "passenger_throughput": 7183.636363636364,
      "memory_size": 11700
    },
    {
      "episode": 40,
      "scenario": "Day 20250715, Cycle 3",
      "reward": -352.25755814402885,
      "steps": 300,
      "time_minutes": 4.055492305755616,
      "avg_loss": 0.0663911440099279,
      "epsilon": 0.009995187929535779,
      "vehicles": 333,
      "completed_trips": 468,
      "passenger_throughput": 7658.181818181819,
      "memory_size": 12000
    },
    {
      "episode": 41,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -306.54393889491104,
      "steps": 300,
      "time_minutes": 4.076821255683899,
      "avg_loss": 0.11453389118115108,
      "epsilon": 0.009995187929535779,
      "vehicles": 364,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 12300
    },
    {
      "episode": 42,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -299.1296718373832,
      "steps": 300,
      "time_minutes": 4.042086184024811,
      "avg_loss": 0.10392781523366769,
      "epsilon": 0.009995187929535779,
      "vehicles": 313,
      "completed_trips": 453,
      "passenger_throughput": 7412.727272727273,
      "memory_size": 12600
    },
    {
      "episode": 43,
      "scenario": "Day 20250704, Cycle 1",
      "reward": -348.66626155394886,
      "steps": 300,
      "time_minutes": 4.0761321663856505,
      "avg_loss": 0.10122429195791482,
      "epsilon": 0.009995187929535779,
      "vehicles": 352,
      "completed_trips": 492,
      "passenger_throughput": 8050.909090909092,
      "memory_size": 12900
    },
    {
      "episode": 44,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -357.3294720770827,
      "steps": 300,
      "time_minutes": 4.093336033821106,
      "avg_loss": 0.0953194592272242,
      "epsilon": 0.009995187929535779,
      "vehicles": 366,
      "completed_trips": 532,
      "passenger_throughput": 8705.454545454546,
      "memory_size": 13200
    },
    {
      "episode": 45,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -368.137002317895,
      "steps": 300,
      "time_minutes": 4.085109655062357,
      "avg_loss": 0.097174220358332,
      "epsilon": 0.009995187929535779,
      "vehicles": 363,
      "completed_trips": 485,
      "passenger_throughput": 7936.363636363637,
      "memory_size": 13500
    },
    {
      "episode": 46,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -221.21327120217302,
      "steps": 300,
      "time_minutes": 4.064352341492971,
      "avg_loss": 0.09001982126384973,
      "epsilon": 0.009995187929535779,
      "vehicles": 343,
      "completed_trips": 516,
      "passenger_throughput": 8443.636363636364,
      "memory_size": 13800
    },
    {
      "episode": 47,
      "scenario": "Day 20250804, Cycle 1",
      "reward": -368.5245367799514,
      "steps": 300,
      "time_minutes": 4.064381710688273,
      "avg_loss": 0.0941855163872242,
      "epsilon": 0.009995187929535779,
      "vehicles": 356,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 14100
    },
    {
      "episode": 48,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -355.4271952253281,
      "steps": 300,
      "time_minutes": 4.071391129493714,
      "avg_loss": 0.0928110200415055,
      "epsilon": 0.009995187929535779,
      "vehicles": 359,
      "completed_trips": 514,
      "passenger_throughput": 8410.909090909092,
      "memory_size": 14400
    },
    {
      "episode": 49,
      "scenario": "Day 20250807, Cycle 2",
      "reward": -439.1269722162202,
      "steps": 300,
      "time_minutes": 4.080200882752736,
      "avg_loss": 0.08605450515945752,
      "epsilon": 0.009995187929535779,
      "vehicles": 374,
      "completed_trips": 488,
      "passenger_throughput": 7985.454545454546,
      "memory_size": 14700
    },
    {
      "episode": 50,
      "scenario": "Day 20250709, Cycle 2",
      "reward": -314.0799023374353,
      "steps": 300,
      "time_minutes": 4.045429813861847,
      "avg_loss": 0.0839233490700523,
      "epsilon": 0.009995187929535779,
      "vehicles": 321,
      "completed_trips": 466,
      "passenger_throughput": 7625.454545454546,
      "memory_size": 15000
    },
    {
      "episode": 51,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -316.4323934000661,
      "steps": 300,
      "time_minutes": 4.0613369901975,
      "avg_loss": 0.1318816033999125,
      "epsilon": 0.009995187929535779,
      "vehicles": 350,
      "completed_trips": 485,
      "passenger_throughput": 7936.363636363637,
      "memory_size": 15300
    },
    {
      "episode": 52,
      "scenario": "Day 20250716, Cycle 2",
      "reward": -389.08388484007315,
      "steps": 300,
      "time_minutes": 4.082017024358113,
      "avg_loss": 0.12216082179298003,
      "epsilon": 0.009995187929535779,
      "vehicles": 345,
      "completed_trips": 522,
      "passenger_throughput": 8541.818181818182,
      "memory_size": 15600
    },
    {
      "episode": 53,
      "scenario": "Day 20250818, Cycle 2",
      "reward": -330.803411719343,
      "steps": 300,
      "time_minutes": 4.0622848749160765,
      "avg_loss": 0.11764464279015859,
      "epsilon": 0.009995187929535779,
      "vehicles": 343,
      "completed_trips": 472,
      "passenger_throughput": 7723.636363636364,
      "memory_size": 15900
    },
    {
      "episode": 54,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -331.34912406142547,
      "steps": 300,
      "time_minutes": 4.052739854653677,
      "avg_loss": 0.11281564092884461,
      "epsilon": 0.009995187929535779,
      "vehicles": 311,
      "completed_trips": 455,
      "passenger_throughput": 7445.454545454546,
      "memory_size": 16200
    },
    {
      "episode": 55,
      "scenario": "Day 20250716, Cycle 3",
      "reward": -336.6901270677301,
      "steps": 300,
      "time_minutes": 4.083814148108164,
      "avg_loss": 0.10727817388872306,
      "epsilon": 0.009995187929535779,
      "vehicles": 370,
      "completed_trips": 506,
      "passenger_throughput": 8280.0,
      "memory_size": 16500
    },
    {
      "episode": 56,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -377.52108464430825,
      "steps": 300,
      "time_minutes": 4.07991658449173,
      "avg_loss": 0.10853189773857594,
      "epsilon": 0.009995187929535779,
      "vehicles": 351,
      "completed_trips": 464,
      "passenger_throughput": 7592.727272727273,
      "memory_size": 16800
    },
    {
      "episode": 57,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -322.18565244614393,
      "steps": 300,
      "time_minutes": 4.094994072119395,
      "avg_loss": 0.10637576585014662,
      "epsilon": 0.009995187929535779,
      "vehicles": 351,
      "completed_trips": 513,
      "passenger_throughput": 8394.545454545456,
      "memory_size": 17100
    },
    {
      "episode": 58,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -340.1776649384089,
      "steps": 300,
      "time_minutes": 4.099919438362122,
      "avg_loss": 0.10516861791412035,
      "epsilon": 0.009995187929535779,
      "vehicles": 366,
      "completed_trips": 525,
      "passenger_throughput": 8590.909090909092,
      "memory_size": 17400
    },
    {
      "episode": 59,
      "scenario": "Day 20250708, Cycle 1",
      "reward": -338.44685840308097,
      "steps": 300,
      "time_minutes": 4.073686945438385,
      "avg_loss": 0.10411780744791031,
      "epsilon": 0.009995187929535779,
      "vehicles": 322,
      "completed_trips": 464,
      "passenger_throughput": 7592.727272727273,
      "memory_size": 17700
    },
    {
      "episode": 60,
      "scenario": "Day 20250807, Cycle 3",
      "reward": -320.635818354495,
      "steps": 300,
      "time_minutes": 4.0787118673324585,
      "avg_loss": 0.09439112202574809,
      "epsilon": 0.009995187929535779,
      "vehicles": 340,
      "completed_trips": 484,
      "passenger_throughput": 7920.000000000001,
      "memory_size": 18000
    },
    {
      "episode": 61,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -415.5933365013826,
      "steps": 300,
      "time_minutes": 4.105450844764709,
      "avg_loss": 0.12576761486629645,
      "epsilon": 0.009995187929535779,
      "vehicles": 357,
      "completed_trips": 522,
      "passenger_throughput": 8541.818181818182,
      "memory_size": 18300
    },
    {
      "episode": 62,
      "scenario": "Day 20250809, Cycle 3",
      "reward": -361.2199556978867,
      "steps": 300,
      "time_minutes": 4.1835533340771995,
      "avg_loss": 0.1115361342082421,
      "epsilon": 0.009995187929535779,
      "vehicles": 353,
      "completed_trips": 486,
      "passenger_throughput": 7952.727272727273,
      "memory_size": 18600
    },
    {
      "episode": 63,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -359.3231639114379,
      "steps": 300,
      "time_minutes": 4.211784076690674,
      "avg_loss": 0.11245652702947458,
      "epsilon": 0.009995187929535779,
      "vehicles": 364,
      "completed_trips": 529,
      "passenger_throughput": 8656.363636363638,
      "memory_size": 18900
    },
    {
      "episode": 64,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -354.6729930286851,
      "steps": 300,
      "time_minutes": 4.175415376822154,
      "avg_loss": 0.10790104545652866,
      "epsilon": 0.009995187929535779,
      "vehicles": 333,
      "completed_trips": 498,
      "passenger_throughput": 8149.09090909091,
      "memory_size": 19200
    },
    {
      "episode": 65,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -425.2938539203959,
      "steps": 300,
      "time_minutes": 4.2678460597991945,
      "avg_loss": 0.10691433776170016,
      "epsilon": 0.009995187929535779,
      "vehicles": 365,
      "completed_trips": 519,
      "passenger_throughput": 8492.727272727274,
      "memory_size": 19500
    },
    {
      "episode": 66,
      "scenario": "Day 20250821, Cycle 2",
      "reward": -288.6080131343655,
      "steps": 300,
      "time_minutes": 4.082997190952301,
      "avg_loss": 0.10275056678801775,
      "epsilon": 0.009995187929535779,
      "vehicles": 338,
      "completed_trips": 481,
      "passenger_throughput": 7870.909090909092,
      "memory_size": 19800
    },
    {
      "episode": 67,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -415.9918569055385,
      "steps": 300,
      "time_minutes": 4.109935986995697,
      "avg_loss": 0.10411384771267573,
      "epsilon": 0.009995187929535779,
      "vehicles": 356,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 20100
    },
    {
      "episode": 68,
      "scenario": "Day 20250709, Cycle 3",
      "reward": -326.9296204260168,
      "steps": 300,
      "time_minutes": 4.072381043434143,
      "avg_loss": 0.09835665166378021,
      "epsilon": 0.009995187929535779,
      "vehicles": 307,
      "completed_trips": 476,
      "passenger_throughput": 7789.09090909091,
      "memory_size": 20400
    },
    {
      "episode": 69,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -340.66063225183626,
      "steps": 300,
      "time_minutes": 4.06611179113388,
      "avg_loss": 0.099962701673309,
      "epsilon": 0.009995187929535779,
      "vehicles": 313,
      "completed_trips": 445,
      "passenger_throughput": 7281.818181818182,
      "memory_size": 20700
    },
    {
      "episode": 70,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -232.28470393468783,
      "steps": 300,
      "time_minutes": 4.072222646077474,
      "avg_loss": 0.09819265338281791,
      "epsilon": 0.009995187929535779,
      "vehicles": 311,
      "completed_trips": 463,
      "passenger_throughput": 7576.363636363637,
      "memory_size": 21000
    },
    {
      "episode": 71,
      "scenario": "Day 20250709, Cycle 1",
      "reward": -331.8663402269185,
      "steps": 300,
      "time_minutes": 3.8444277167320253,
      "avg_loss": 0.14577089394132295,
      "epsilon": 0.009995187929535779,
      "vehicles": 325,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 21300
    },
    {
      "episode": 72,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -362.64054937334606,
      "steps": 300,
      "time_minutes": 3.8522385279337565,
      "avg_loss": 0.14848230101168156,
      "epsilon": 0.009995187929535779,
      "vehicles": 330,
      "completed_trips": 451,
      "passenger_throughput": 7380.000000000001,
      "memory_size": 21600
    },
    {
      "episode": 73,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -425.72523383696733,
      "steps": 300,
      "time_minutes": 3.8914308905601502,
      "avg_loss": 0.13353579313804706,
      "epsilon": 0.009995187929535779,
      "vehicles": 380,
      "completed_trips": 521,
      "passenger_throughput": 8525.454545454546,
      "memory_size": 21900
    },
    {
      "episode": 74,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -268.7163921419183,
      "steps": 300,
      "time_minutes": 3.868559702237447,
      "avg_loss": 0.12737669814378022,
      "epsilon": 0.009995187929535779,
      "vehicles": 329,
      "completed_trips": 509,
      "passenger_throughput": 8329.09090909091,
      "memory_size": 22200
    },
    {
      "episode": 75,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -280.2994280110627,
      "steps": 300,
      "time_minutes": 3.883035349845886,
      "avg_loss": 0.15035195715725422,
      "epsilon": 0.009995187929535779,
      "vehicles": 347,
      "completed_trips": 507,
      "passenger_throughput": 8296.363636363638,
      "memory_size": 22500
    },
    {
      "episode": 76,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -366.56512574341474,
      "steps": 300,
      "time_minutes": 3.9631073315938314,
      "avg_loss": 0.16477764558047056,
      "epsilon": 0.009995187929535779,
      "vehicles": 338,
      "completed_trips": 491,
      "passenger_throughput": 8034.545454545455,
      "memory_size": 22800
    },
    {
      "episode": 77,
      "scenario": "Day 20250709, Cycle 2",
      "reward": -306.6871097405714,
      "steps": 300,
      "time_minutes": 4.12539103825887,
      "avg_loss": 0.15276317494610944,
      "epsilon": 0.009995187929535779,
      "vehicles": 305,
      "completed_trips": 465,
      "passenger_throughput": 7609.09090909091,
      "memory_size": 23100
    },
    {
      "episode": 78,
      "scenario": "Day 20250708, Cycle 1",
      "reward": -328.44977128974375,
      "steps": 300,
      "time_minutes": 3.8599663217862448,
      "avg_loss": 0.131956135990719,
      "epsilon": 0.009995187929535779,
      "vehicles": 313,
      "completed_trips": 476,
      "passenger_throughput": 7789.09090909091,
      "memory_size": 23400
    },
    {
      "episode": 79,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -374.377937695361,
      "steps": 300,
      "time_minutes": 3.879570774237315,
      "avg_loss": 0.11961069874465466,
      "epsilon": 0.009995187929535779,
      "vehicles": 360,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 23700
    },
    {
      "episode": 80,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -390.23032949604624,
      "steps": 300,
      "time_minutes": 3.8744423508644106,
      "avg_loss": 0.10189603122572104,
      "epsilon": 0.009995187929535779,
      "vehicles": 355,
      "completed_trips": 499,
      "passenger_throughput": 8165.454545454546,
      "memory_size": 24000
    },
    {
      "episode": 81,
      "scenario": "Day 20250804, Cycle 1",
      "reward": -378.95418896206905,
      "steps": 300,
      "time_minutes": 3.875826402505239,
      "avg_loss": 0.08890441752970218,
      "epsilon": 0.009995187929535779,
      "vehicles": 352,
      "completed_trips": 480,
      "passenger_throughput": 7854.545454545455,
      "memory_size": 24300
    },
    {
      "episode": 82,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -380.5753239760068,
      "steps": 300,
      "time_minutes": 3.867172968387604,
      "avg_loss": 0.08107329732427994,
      "epsilon": 0.009995187929535779,
      "vehicles": 347,
      "completed_trips": 487,
      "passenger_throughput": 7969.09090909091,
      "memory_size": 24600
    },
    {
      "episode": 83,
      "scenario": "Day 20250807, Cycle 3",
      "reward": -391.07197712594115,
      "steps": 300,
      "time_minutes": 3.866899299621582,
      "avg_loss": 0.08034514373789231,
      "epsilon": 0.009995187929535779,
      "vehicles": 350,
      "completed_trips": 467,
      "passenger_throughput": 7641.818181818182,
      "memory_size": 24900
    },
    {
      "episode": 84,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -336.6901849250188,
      "steps": 300,
      "time_minutes": 3.8425341407457987,
      "avg_loss": 0.07714959972848495,
      "epsilon": 0.009995187929535779,
      "vehicles": 303,
      "completed_trips": 443,
      "passenger_throughput": 7249.09090909091,
      "memory_size": 25200
    },
    {
      "episode": 85,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -348.35815927573987,
      "steps": 300,
      "time_minutes": 3.8659940282503764,
      "avg_loss": 0.07614461090415717,
      "epsilon": 0.009995187929535779,
      "vehicles": 350,
      "completed_trips": 479,
      "passenger_throughput": 7838.181818181819,
      "memory_size": 25500
    },
    {
      "episode": 86,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -337.4267145141796,
      "steps": 300,
      "time_minutes": 3.8589794913927715,
      "avg_loss": 0.07582605427751939,
      "epsilon": 0.009995187929535779,
      "vehicles": 320,
      "completed_trips": 462,
      "passenger_throughput": 7560.000000000001,
      "memory_size": 25800
    },
    {
      "episode": 87,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -387.545635175117,
      "steps": 300,
      "time_minutes": 3.885394310951233,
      "avg_loss": 0.07788339344163736,
      "epsilon": 0.009995187929535779,
      "vehicles": 363,
      "completed_trips": 507,
      "passenger_throughput": 8296.363636363638,
      "memory_size": 26100
    },
    {
      "episode": 88,
      "scenario": "Day 20250709, Cycle 3",
      "reward": -369.2507895178187,
      "steps": 300,
      "time_minutes": 3.8613015174865724,
      "avg_loss": 0.07353339647253354,
      "epsilon": 0.009995187929535779,
      "vehicles": 326,
      "completed_trips": 465,
      "passenger_throughput": 7609.09090909091,
      "memory_size": 26400
    },
    {
      "episode": 89,
      "scenario": "Day 20250807, Cycle 2",
      "reward": -377.5298326626759,
      "steps": 300,
      "time_minutes": 3.8891190767288206,
      "avg_loss": 0.07650429297238588,
      "epsilon": 0.009995187929535779,
      "vehicles": 358,
      "completed_trips": 487,
      "passenger_throughput": 7969.09090909091,
      "memory_size": 26700
    },
    {
      "episode": 90,
      "scenario": "Day 20250704, Cycle 3",
      "reward": -383.05759712673984,
      "steps": 300,
      "time_minutes": 3.894503819942474,
      "avg_loss": 0.08070241442571084,
      "epsilon": 0.009995187929535779,
      "vehicles": 372,
      "completed_trips": 494,
      "passenger_throughput": 8083.636363636364,
      "memory_size": 27000
    },
    {
      "episode": 91,
      "scenario": "Day 20250704, Cycle 1",
      "reward": -358.7235548136161,
      "steps": 300,
      "time_minutes": 3.882556664943695,
      "avg_loss": 0.13589259774734577,
      "epsilon": 0.009995187929535779,
      "vehicles": 345,
      "completed_trips": 500,
      "passenger_throughput": 8181.818181818182,
      "memory_size": 27300
    },
    {
      "episode": 92,
      "scenario": "Day 20250716, Cycle 2",
      "reward": -285.07096644184344,
      "steps": 300,
      "time_minutes": 3.881308909257253,
      "avg_loss": 0.12899973437190057,
      "epsilon": 0.009995187929535779,
      "vehicles": 345,
      "completed_trips": 518,
      "passenger_throughput": 8476.363636363638,
      "memory_size": 27600
    },
    {
      "episode": 93,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -380.9400879416811,
      "steps": 300,
      "time_minutes": 3.8988179643948873,
      "avg_loss": 0.13269843963285288,
      "epsilon": 0.009995187929535779,
      "vehicles": 360,
      "completed_trips": 535,
      "passenger_throughput": 8754.545454545456,
      "memory_size": 27900
    },
    {
      "episode": 94,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -423.94020201376446,
      "steps": 300,
      "time_minutes": 3.9073206702868144,
      "avg_loss": 0.1278422735258937,
      "epsilon": 0.009995187929535779,
      "vehicles": 370,
      "completed_trips": 509,
      "passenger_throughput": 8329.09090909091,
      "memory_size": 28200
    },
    {
      "episode": 95,
      "scenario": "Day 20250805, Cycle 1",
      "reward": -442.40938518347383,
      "steps": 300,
      "time_minutes": 3.902604575951894,
      "avg_loss": 0.1202003838121891,
      "epsilon": 0.009995187929535779,
      "vehicles": 362,
      "completed_trips": 503,
      "passenger_throughput": 8230.909090909092,
      "memory_size": 28500
    },
    {
      "episode": 96,
      "scenario": "Day 20250710, Cycle 2",
      "reward": -313.68810956255703,
      "steps": 300,
      "time_minutes": 3.861550239721934,
      "avg_loss": 0.1311081131050984,
      "epsilon": 0.009995187929535779,
      "vehicles": 281,
      "completed_trips": 466,
      "passenger_throughput": 7625.454545454546,
      "memory_size": 28800
    },
    {
      "episode": 97,
      "scenario": "Day 20250815, Cycle 3",
      "reward": -339.45115248237676,
      "steps": 300,
      "time_minutes": 3.8676228483517963,
      "avg_loss": 0.118323893075188,
      "epsilon": 0.009995187929535779,
      "vehicles": 317,
      "completed_trips": 484,
      "passenger_throughput": 7920.000000000001,
      "memory_size": 29100
    },
    {
      "episode": 98,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -409.3495704227689,
      "steps": 300,
      "time_minutes": 3.882983199755351,
      "avg_loss": 0.11560043589522441,
      "epsilon": 0.009995187929535779,
      "vehicles": 340,
      "completed_trips": 453,
      "passenger_throughput": 7412.727272727273,
      "memory_size": 29400
    },
    {
      "episode": 99,
      "scenario": "Day 20250818, Cycle 2",
      "reward": -405.1068983004687,
      "steps": 300,
      "time_minutes": 3.8876351952552795,
      "avg_loss": 0.1182238460580508,
      "epsilon": 0.009995187929535779,
      "vehicles": 343,
      "completed_trips": 465,
      "passenger_throughput": 7609.09090909091,
      "memory_size": 29700
    },
    {
      "episode": 100,
      "scenario": "Day 20250812, Cycle 3",
      "reward": -331.63517768128963,
      "steps": 300,
      "time_minutes": 3.9004323641459147,
      "avg_loss": 0.11828839094688495,
      "epsilon": 0.009995187929535779,
      "vehicles": 367,
      "completed_trips": 505,
      "passenger_throughput": 8263.636363636364,
      "memory_size": 30000
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -391.6554873354157,
      "reward_std": 42.56447499583201,
      "avg_vehicles": 357.0,
      "avg_completed_trips": 481.4,
      "avg_passenger_throughput": 7877.454545454546,
      "scenarios_tested": 10
    },
    {
      "episode": 30,
      "avg_reward": -385.2211569811448,
      "reward_std": 30.85523603202752,
      "avg_vehicles": 353.8,
      "avg_completed_trips": 480.8,
      "avg_passenger_throughput": 7867.636363636365,
      "scenarios_tested": 10
    },
    {
      "episode": 45,
      "avg_reward": -381.47153344403773,
      "reward_std": 23.732879265645852,
      "avg_vehicles": 353.2,
      "avg_completed_trips": 480.9,
      "avg_passenger_throughput": 7869.272727272726,
      "scenarios_tested": 10
    },
    {
      "episode": 60,
      "avg_reward": -393.87988154567995,
      "reward_std": 26.161481176132416,
      "avg_vehicles": 353.4,
      "avg_completed_trips": 487.1,
      "avg_passenger_throughput": 7970.727272727274,
      "scenarios_tested": 10
    },
    {
      "episode": 75,
      "avg_reward": -385.09046602562114,
      "reward_std": 27.486255448668413,
      "avg_vehicles": 351.8,
      "avg_completed_trips": 478.4,
      "avg_passenger_throughput": 7828.363636363637,
      "scenarios_tested": 10
    },
    {
      "episode": 90,
      "avg_reward": -384.53553551910727,
      "reward_std": 31.623276515328154,
      "avg_vehicles": 355.0,
      "avg_completed_trips": 480.6,
      "avg_passenger_throughput": 7864.363636363637,
      "scenarios_tested": 10
    }
  ],
  "final_evaluation": {
    "test_scenarios": 7,
    "comparison_results": null,
    "evaluation_timestamp": "2025-10-18T05:10:20.021539"
  },
  "logger_summary": {
    "experiment_id": "verification_100ep_batch64",
    "session_id": "a9dc08ba-8c94-4720-820a-4679185de6f1",
    "timestamp": "2025-10-18T05:10:20.028521",
    "total_episodes": 50,
    "performance_metrics": {
      "avg_reward": -1.1826825250165203,
      "best_reward": -0.7742823464489598,
      "reward_improvement": -5.5664311709025505,
      "avg_passenger_throughput": 7975.963636363636,
      "avg_vehicles_served": 487.42,
      "avg_pt_throughput": 2908.64
    },
    "learning_metrics": {
      "convergence_episode": -1,
      "stability_score": 0.8769203565375557,
      "exploration_rate": 1.1541438406118651
    },
    "config": {
      "log_interval": 30,
      "buffer_size": 100,
      "total_steps": 14950
    }
  },
  "defense_ready": true,
  "timestamp": "2025-10-18T05:10:20.029521"
}