{
  "experiment_name": "verification_20ep_20251017_104655",
  "config": {
    "experiment_name": "verification_20ep_20251017_104655",
    "learning_rate": 0.0005,
    "epsilon_decay": 0.9995,
    "memory_size": 50000,
    "batch_size": 128,
    "gamma": 0.98,
    "sequence_length": 10,
    "episodes": 20,
    "target_update_freq": 10,
    "save_freq": 25,
    "validation_freq": 15,
    "episode_duration": 300,
    "warmup_time": 30,
    "min_phase_time": 12,
    "max_phase_time": 120,
    "random_seed": 42,
    "validation_episodes": 10,
    "agent_type": "lstm",
    "offline_episodes": 14,
    "online_episodes": 6
  },
  "training_time_minutes": 84.49128888050716,
  "best_reward": -312.2976263781451,
  "convergence_episode": -1,
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -344.43710996782073,
      "steps": 300,
      "time_minutes": 2.724944790204366,
      "avg_loss": 0.08753882257571054,
      "epsilon": 0.917574496577849,
      "vehicles": 355,
      "completed_trips": 492,
      "passenger_throughput": 8050.909090909092,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -358.1457471277059,
      "steps": 300,
      "time_minutes": 3.8684165755907696,
      "avg_loss": 0.06557679180055857,
      "epsilon": 0.7897340627103864,
      "vehicles": 347,
      "completed_trips": 503,
      "passenger_throughput": 8230.909090909092,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -330.31494015870294,
      "steps": 300,
      "time_minutes": 3.907096266746521,
      "avg_loss": 0.05592125390966733,
      "epsilon": 0.6797049091175745,
      "vehicles": 355,
      "completed_trips": 523,
      "passenger_throughput": 8558.181818181818,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -340.3272473805008,
      "steps": 300,
      "time_minutes": 3.938408041000366,
      "avg_loss": 0.044874500464648005,
      "epsilon": 0.5850054914599224,
      "vehicles": 333,
      "completed_trips": 526,
      "passenger_throughput": 8607.272727272728,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -320.9688052485439,
      "steps": 300,
      "time_minutes": 3.950672137737274,
      "avg_loss": 0.03837035487095515,
      "epsilon": 0.5035000048514676,
      "vehicles": 308,
      "completed_trips": 467,
      "passenger_throughput": 7641.818181818182,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -316.18170039380874,
      "steps": 300,
      "time_minutes": 3.9790051658948262,
      "avg_loss": 0.03609216595689456,
      "epsilon": 0.43335021394888135,
      "vehicles": 339,
      "completed_trips": 499,
      "passenger_throughput": 8165.454545454546,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -361.32142203395205,
      "steps": 300,
      "time_minutes": 3.9920422792434693,
      "avg_loss": 0.034625982102006674,
      "epsilon": 0.37297399428017836,
      "vehicles": 363,
      "completed_trips": 476,
      "passenger_throughput": 7789.09090909091,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -356.04278866663793,
      "steps": 300,
      "time_minutes": 4.017684272925059,
      "avg_loss": 0.03298339734474818,
      "epsilon": 0.32100964977421276,
      "vehicles": 357,
      "completed_trips": 485,
      "passenger_throughput": 7936.363636363637,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -330.84827259661967,
      "steps": 300,
      "time_minutes": 4.052934539318085,
      "avg_loss": 0.03113196948543191,
      "epsilon": 0.27628520172576376,
      "vehicles": 339,
      "completed_trips": 495,
      "passenger_throughput": 8100.000000000001,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -365.47296576639343,
      "steps": 300,
      "time_minutes": 4.068809409936269,
      "avg_loss": 0.028355905742694934,
      "epsilon": 0.2377919565543782,
      "vehicles": 367,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -383.9500307749383,
      "steps": 300,
      "time_minutes": 4.096778857707977,
      "avg_loss": 0.0645119512702028,
      "epsilon": 0.20466175621698698,
      "vehicles": 373,
      "completed_trips": 506,
      "passenger_throughput": 8280.0,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -371.3607784775827,
      "steps": 300,
      "time_minutes": 4.096052757898966,
      "avg_loss": 0.05576297697921594,
      "epsilon": 0.1761473981910859,
      "vehicles": 361,
      "completed_trips": 488,
      "passenger_throughput": 7985.454545454546,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -353.8897241371043,
      "steps": 300,
      "time_minutes": 4.082059725125631,
      "avg_loss": 0.04974861916775505,
      "epsilon": 0.15160578343025852,
      "vehicles": 296,
      "completed_trips": 480,
      "passenger_throughput": 7854.545454545455,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -413.24921381470904,
      "steps": 300,
      "time_minutes": 4.141452562808991,
      "avg_loss": 0.04749273064856728,
      "epsilon": 0.13048341221917423,
      "vehicles": 405,
      "completed_trips": 494,
      "passenger_throughput": 8083.636363636364,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -360.8806687026691,
      "steps": 300,
      "time_minutes": 3.9095066666603087,
      "avg_loss": 0.046837544019023576,
      "epsilon": 0.12288391244506353,
      "vehicles": 333,
      "completed_trips": 465,
      "passenger_throughput": 7609.09090909091,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -369.716935103695,
      "steps": 300,
      "time_minutes": 3.8964718262354534,
      "avg_loss": 0.04283018007253607,
      "epsilon": 0.11572701603205837,
      "vehicles": 333,
      "completed_trips": 456,
      "passenger_throughput": 7461.818181818182,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -393.34728584814525,
      "steps": 300,
      "time_minutes": 3.926183863480886,
      "avg_loss": 0.0443829718294243,
      "epsilon": 0.10898694526569244,
      "vehicles": 393,
      "completed_trips": 518,
      "passenger_throughput": 8476.363636363638,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -392.1338894298535,
      "steps": 300,
      "time_minutes": 3.904042299588521,
      "avg_loss": 0.04224217134838303,
      "epsilon": 0.1026394237544031,
      "vehicles": 329,
      "completed_trips": 513,
      "passenger_throughput": 8394.545454545456,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -399.43369560932615,
      "steps": 300,
      "time_minutes": 3.9341462731361387,
      "avg_loss": 0.04500801738972465,
      "epsilon": 0.09666158899080693,
      "vehicles": 364,
      "completed_trips": 494,
      "passenger_throughput": 8083.636363636364,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -312.2976263781451,
      "steps": 300,
      "time_minutes": 3.9039524157842,
      "avg_loss": 0.0410856733036538,
      "epsilon": 0.09103191000550485,
      "vehicles": 339,
      "completed_trips": 508,
      "passenger_throughput": 8312.727272727274,
      "memory_size": 6000
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -376.7196368926492,
      "reward_std": 34.157552030727956,
      "avg_vehicles": 352.5,
      "avg_completed_trips": 483.6,
      "avg_passenger_throughput": 7913.454545454547,
      "scenarios_tested": 10
    }
  ],
  "final_evaluation": {
    "test_scenarios": 7,
    "comparison_results": null,
    "evaluation_timestamp": "2025-10-17T12:17:13.754902"
  },
  "logger_summary": {
    "experiment_id": "verification_20ep_20251017_104655",
    "session_id": "5353b639-5569-4d31-a692-a74a645e6468",
    "timestamp": "2025-10-17T12:17:13.758919",
    "total_episodes": 20,
    "performance_metrics": {
      "avg_reward": -1.1957201412694756,
      "best_reward": -1.0409920879271504,
      "reward_improvement": -10.195738964451607,
      "avg_passenger_throughput": 8069.727272727272,
      "avg_vehicles_served": 493.15,
      "avg_pt_throughput": 2940.4
    },
    "learning_metrics": {
      "convergence_episode": -1,
      "stability_score": 0.9224748270303552,
      "exploration_rate": 1.3071600606653389
    },
    "config": {
      "log_interval": 30,
      "buffer_size": 100,
      "total_steps": 5980
    }
  },
  "defense_ready": true,
  "timestamp": "2025-10-17T12:17:13.759886"
}