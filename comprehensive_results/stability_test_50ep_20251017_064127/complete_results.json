{
  "experiment_name": "stability_test_50ep_20251017_064127",
  "config": {
    "experiment_name": "stability_test_50ep_20251017_064127",
    "learning_rate": 0.00025,
    "epsilon_decay": 0.9995,
    "memory_size": 50000,
    "batch_size": 96,
    "gamma": 0.98,
    "sequence_length": 10,
    "episodes": 50,
    "target_update_freq": 10,
    "save_freq": 25,
    "validation_freq": 15,
    "episode_duration": 300,
    "warmup_time": 30,
    "min_phase_time": 12,
    "max_phase_time": 120,
    "random_seed": 42,
    "validation_episodes": 10,
    "agent_type": "lstm",
    "offline_episodes": 35,
    "online_episodes": 15
  },
  "training_time_minutes": 229.76803152958553,
  "best_reward": -236.45808211941068,
  "convergence_episode": -1,
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -436.32297511132526,
      "steps": 300,
      "time_minutes": 3.1556270996729534,
      "avg_loss": 0.17676170809450104,
      "epsilon": 0.9030065170304803,
      "vehicles": 358,
      "completed_trips": 501,
      "passenger_throughput": 8198.181818181818,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -391.3237849348994,
      "steps": 300,
      "time_minutes": 4.184612437089284,
      "avg_loss": 0.10529683078328768,
      "epsilon": 0.7771957568656473,
      "vehicles": 367,
      "completed_trips": 481,
      "passenger_throughput": 7870.909090909092,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -362.92368018442403,
      "steps": 300,
      "time_minutes": 4.074774444103241,
      "avg_loss": 0.0904208396996061,
      "epsilon": 0.6689134940867506,
      "vehicles": 367,
      "completed_trips": 528,
      "passenger_throughput": 8640.0,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -240.05577363528576,
      "steps": 300,
      "time_minutes": 4.087553973992666,
      "avg_loss": 0.09318642990042766,
      "epsilon": 0.5757175828852275,
      "vehicles": 343,
      "completed_trips": 507,
      "passenger_throughput": 8296.363636363638,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -325.22369718216135,
      "steps": 300,
      "time_minutes": 4.108317271868388,
      "avg_loss": 0.08073796790093184,
      "epsilon": 0.49550612773289854,
      "vehicles": 308,
      "completed_trips": 469,
      "passenger_throughput": 7674.545454545455,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -382.05240746674167,
      "steps": 300,
      "time_minutes": 4.145342230796814,
      "avg_loss": 0.07737243084857862,
      "epsilon": 0.42647007824633054,
      "vehicles": 345,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -396.7416758972024,
      "steps": 300,
      "time_minutes": 4.166053001085917,
      "avg_loss": 0.07132551268984874,
      "epsilon": 0.36705242873902766,
      "vehicles": 355,
      "completed_trips": 473,
      "passenger_throughput": 7740.000000000001,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -345.63726183717404,
      "steps": 300,
      "time_minutes": 4.176641217867533,
      "avg_loss": 0.06425212738414605,
      "epsilon": 0.3159131022678686,
      "vehicles": 363,
      "completed_trips": 478,
      "passenger_throughput": 7821.818181818182,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -404.27363151198705,
      "steps": 300,
      "time_minutes": 4.183476177851359,
      "avg_loss": 0.06215035311877728,
      "epsilon": 0.2718987271855571,
      "vehicles": 350,
      "completed_trips": 493,
      "passenger_throughput": 8067.272727272728,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -350.2578879080246,
      "steps": 300,
      "time_minutes": 4.208714314301809,
      "avg_loss": 0.05451526942973336,
      "epsilon": 0.23401662455405253,
      "vehicles": 352,
      "completed_trips": 491,
      "passenger_throughput": 8034.545454545455,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -402.61856667841937,
      "steps": 300,
      "time_minutes": 4.227544689178467,
      "avg_loss": 0.11423082505663236,
      "epsilon": 0.20141241974368984,
      "vehicles": 368,
      "completed_trips": 500,
      "passenger_throughput": 8181.818181818182,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -415.1338730670516,
      "steps": 300,
      "time_minutes": 4.238390044371287,
      "avg_loss": 0.0952057401339213,
      "epsilon": 0.1733507732808029,
      "vehicles": 356,
      "completed_trips": 474,
      "passenger_throughput": 7756.363636363637,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -380.72276761169167,
      "steps": 300,
      "time_minutes": 4.206096426645915,
      "avg_loss": 0.08699218492954969,
      "epsilon": 0.14919879635671626,
      "vehicles": 309,
      "completed_trips": 445,
      "passenger_throughput": 7281.818181818182,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -399.3018663472281,
      "steps": 300,
      "time_minutes": 4.250999037424723,
      "avg_loss": 0.0829652893791596,
      "epsilon": 0.1284117769595095,
      "vehicles": 404,
      "completed_trips": 499,
      "passenger_throughput": 8165.454545454546,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -236.45808211941068,
      "steps": 300,
      "time_minutes": 4.2255930542945865,
      "avg_loss": 0.08524992920458317,
      "epsilon": 0.11052089470262352,
      "vehicles": 321,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -323.95398931620645,
      "steps": 300,
      "time_minutes": 4.224290601412455,
      "avg_loss": 0.08751294781764349,
      "epsilon": 0.09512264727650294,
      "vehicles": 327,
      "completed_trips": 469,
      "passenger_throughput": 7674.545454545455,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -320.6901358513346,
      "steps": 300,
      "time_minutes": 4.247745664914449,
      "avg_loss": 0.08009180453916391,
      "epsilon": 0.08186975005256825,
      "vehicles": 348,
      "completed_trips": 496,
      "passenger_throughput": 8116.363636363637,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -283.32228131546447,
      "steps": 300,
      "time_minutes": 4.240768146514893,
      "avg_loss": 0.07018059376627207,
      "epsilon": 0.07046330359358775,
      "vehicles": 322,
      "completed_trips": 518,
      "passenger_throughput": 8476.363636363638,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -311.8232230527033,
      "steps": 300,
      "time_minutes": 4.259103838602702,
      "avg_loss": 0.06735853648434083,
      "epsilon": 0.06064605242026579,
      "vehicles": 351,
      "completed_trips": 517,
      "passenger_throughput": 8460.0,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -427.5053410110783,
      "steps": 300,
      "time_minutes": 4.252405305703481,
      "avg_loss": 0.06779032005618016,
      "epsilon": 0.052196582995525806,
      "vehicles": 340,
      "completed_trips": 494,
      "passenger_throughput": 8083.636363636364,
      "memory_size": 6000
    },
    {
      "episode": 21,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -428.68871367909054,
      "steps": 300,
      "time_minutes": 4.266639216740926,
      "avg_loss": 0.06713097371160984,
      "epsilon": 0.044924330070630965,
      "vehicles": 339,
      "completed_trips": 468,
      "passenger_throughput": 7658.181818181819,
      "memory_size": 6300
    },
    {
      "episode": 22,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -361.4649571612674,
      "steps": 300,
      "time_minutes": 4.255436996618907,
      "avg_loss": 0.06300954109678666,
      "epsilon": 0.03866527876868863,
      "vehicles": 312,
      "completed_trips": 456,
      "passenger_throughput": 7461.818181818182,
      "memory_size": 6600
    },
    {
      "episode": 23,
      "scenario": "Day 20250716, Cycle 3",
      "reward": -304.34553014942094,
      "steps": 300,
      "time_minutes": 4.279900860786438,
      "avg_loss": 0.07485493753105402,
      "epsilon": 0.033278265472405005,
      "vehicles": 359,
      "completed_trips": 509,
      "passenger_throughput": 8329.09090909091,
      "memory_size": 6900
    },
    {
      "episode": 24,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -281.4992385528736,
      "steps": 300,
      "time_minutes": 4.252789052327474,
      "avg_loss": 0.08892304720977942,
      "epsilon": 0.02864179408810256,
      "vehicles": 314,
      "completed_trips": 465,
      "passenger_throughput": 7609.09090909091,
      "memory_size": 7200
    },
    {
      "episode": 25,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -347.16515041100723,
      "steps": 300,
      "time_minutes": 4.270215054353078,
      "avg_loss": 0.0833609809850653,
      "epsilon": 0.024651295881557247,
      "vehicles": 345,
      "completed_trips": 494,
      "passenger_throughput": 8083.636363636364,
      "memory_size": 7500
    },
    {
      "episode": 26,
      "scenario": "Day 20250811, Cycle 3",
      "reward": -431.01881054559993,
      "steps": 300,
      "time_minutes": 4.2845442533493046,
      "avg_loss": 0.0802315966784954,
      "epsilon": 0.021216771085317825,
      "vehicles": 364,
      "completed_trips": 484,
      "passenger_throughput": 7920.000000000001,
      "memory_size": 7800
    },
    {
      "episode": 27,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -337.62673826690485,
      "steps": 300,
      "time_minutes": 4.258990140755971,
      "avg_loss": 0.07816233887026708,
      "epsilon": 0.01826075908745865,
      "vehicles": 296,
      "completed_trips": 474,
      "passenger_throughput": 7756.363636363637,
      "memory_size": 8100
    },
    {
      "episode": 28,
      "scenario": "Day 20250812, Cycle 3",
      "reward": -376.31430578057007,
      "steps": 300,
      "time_minutes": 4.304511467615764,
      "avg_loss": 0.07663441448161999,
      "epsilon": 0.015716591422384595,
      "vehicles": 365,
      "completed_trips": 464,
      "passenger_throughput": 7592.727272727273,
      "memory_size": 8400
    },
    {
      "episode": 29,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -349.59696712126305,
      "steps": 300,
      "time_minutes": 4.300480075677236,
      "avg_loss": 0.0766510529195269,
      "epsilon": 0.013526888162487097,
      "vehicles": 367,
      "completed_trips": 513,
      "passenger_throughput": 8394.545454545456,
      "memory_size": 8700
    },
    {
      "episode": 30,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -304.7165486830014,
      "steps": 300,
      "time_minutes": 4.273240129152934,
      "avg_loss": 0.07103392355144024,
      "epsilon": 0.011642263798995646,
      "vehicles": 314,
      "completed_trips": 476,
      "passenger_throughput": 7789.09090909091,
      "memory_size": 9000
    },
    {
      "episode": 31,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -302.0225881356439,
      "steps": 300,
      "time_minutes": 4.273843693733215,
      "avg_loss": 0.134825443799297,
      "epsilon": 0.010020213425087068,
      "vehicles": 337,
      "completed_trips": 467,
      "passenger_throughput": 7641.818181818182,
      "memory_size": 9300
    },
    {
      "episode": 32,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -419.1861652066162,
      "steps": 300,
      "time_minutes": 4.291257452964783,
      "avg_loss": 0.13807562490304312,
      "epsilon": 0.009995187929535779,
      "vehicles": 345,
      "completed_trips": 495,
      "passenger_throughput": 8100.000000000001,
      "memory_size": 9600
    },
    {
      "episode": 33,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -306.74233837911726,
      "steps": 300,
      "time_minutes": 4.273675906658172,
      "avg_loss": 0.1269111372033755,
      "epsilon": 0.009995187929535779,
      "vehicles": 311,
      "completed_trips": 446,
      "passenger_throughput": 7298.181818181819,
      "memory_size": 9900
    },
    {
      "episode": 34,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -429.1304139412991,
      "steps": 300,
      "time_minutes": 4.318047964572907,
      "avg_loss": 0.14730629794299602,
      "epsilon": 0.009995187929535779,
      "vehicles": 359,
      "completed_trips": 505,
      "passenger_throughput": 8263.636363636364,
      "memory_size": 10200
    },
    {
      "episode": 35,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -334.1349960080493,
      "steps": 300,
      "time_minutes": 4.300899692376455,
      "avg_loss": 0.16946276697019735,
      "epsilon": 0.009995187929535779,
      "vehicles": 337,
      "completed_trips": 498,
      "passenger_throughput": 8149.09090909091,
      "memory_size": 10500
    },
    {
      "episode": 36,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -399.3530201156024,
      "steps": 300,
      "time_minutes": 4.186540496349335,
      "avg_loss": 0.16589175030589104,
      "epsilon": 0.009995187929535779,
      "vehicles": 379,
      "completed_trips": 504,
      "passenger_throughput": 8247.272727272728,
      "memory_size": 10800
    },
    {
      "episode": 37,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -404.1920759090803,
      "steps": 300,
      "time_minutes": 4.16403241554896,
      "avg_loss": 0.16553603338698547,
      "epsilon": 0.009995187929535779,
      "vehicles": 332,
      "completed_trips": 468,
      "passenger_throughput": 7658.181818181819,
      "memory_size": 11100
    },
    {
      "episode": 38,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -423.6335513381662,
      "steps": 300,
      "time_minutes": 4.198741948604583,
      "avg_loss": 0.15469139013439417,
      "epsilon": 0.009995187929535779,
      "vehicles": 399,
      "completed_trips": 506,
      "passenger_throughput": 8280.0,
      "memory_size": 11400
    },
    {
      "episode": 39,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -386.640091173247,
      "steps": 300,
      "time_minutes": 4.163632615407308,
      "avg_loss": 0.20634946095446746,
      "epsilon": 0.009995187929535779,
      "vehicles": 329,
      "completed_trips": 502,
      "passenger_throughput": 8214.545454545456,
      "memory_size": 11700
    },
    {
      "episode": 40,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -369.32840089258684,
      "steps": 300,
      "time_minutes": 4.1873904943466185,
      "avg_loss": 0.20597256104151407,
      "epsilon": 0.009995187929535779,
      "vehicles": 351,
      "completed_trips": 512,
      "passenger_throughput": 8378.181818181818,
      "memory_size": 12000
    },
    {
      "episode": 41,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -336.2690646443739,
      "steps": 300,
      "time_minutes": 4.179786268870036,
      "avg_loss": 0.2275175715982914,
      "epsilon": 0.009995187929535779,
      "vehicles": 337,
      "completed_trips": 502,
      "passenger_throughput": 8214.545454545456,
      "memory_size": 12300
    },
    {
      "episode": 42,
      "scenario": "Day 20250709, Cycle 2",
      "reward": -393.4243008054986,
      "steps": 300,
      "time_minutes": 4.176311000188192,
      "avg_loss": 0.2249040195842584,
      "epsilon": 0.009995187929535779,
      "vehicles": 322,
      "completed_trips": 462,
      "passenger_throughput": 7560.000000000001,
      "memory_size": 12600
    },
    {
      "episode": 43,
      "scenario": "Day 20250708, Cycle 1",
      "reward": -352.1003821306265,
      "steps": 300,
      "time_minutes": 4.185816943645477,
      "avg_loss": 0.2150902643799782,
      "epsilon": 0.009995187929535779,
      "vehicles": 317,
      "completed_trips": 463,
      "passenger_throughput": 7576.363636363637,
      "memory_size": 12900
    },
    {
      "episode": 44,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -370.60626936937865,
      "steps": 300,
      "time_minutes": 4.201668512821198,
      "avg_loss": 0.20807617304225762,
      "epsilon": 0.009995187929535779,
      "vehicles": 337,
      "completed_trips": 493,
      "passenger_throughput": 8067.272727272728,
      "memory_size": 13200
    },
    {
      "episode": 45,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -369.77069913060984,
      "steps": 300,
      "time_minutes": 4.198431531588237,
      "avg_loss": 0.20696412367125352,
      "epsilon": 0.009995187929535779,
      "vehicles": 352,
      "completed_trips": 487,
      "passenger_throughput": 7969.09090909091,
      "memory_size": 13500
    },
    {
      "episode": 46,
      "scenario": "Day 20250804, Cycle 1",
      "reward": -319.9012795079156,
      "steps": 300,
      "time_minutes": 4.255530830224355,
      "avg_loss": 0.20551632933318614,
      "epsilon": 0.009995187929535779,
      "vehicles": 347,
      "completed_trips": 473,
      "passenger_throughput": 7740.000000000001,
      "memory_size": 13800
    },
    {
      "episode": 47,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -345.0284424079391,
      "steps": 300,
      "time_minutes": 4.2840661327044165,
      "avg_loss": 0.20418078588942687,
      "epsilon": 0.009995187929535779,
      "vehicles": 342,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 14100
    },
    {
      "episode": 48,
      "scenario": "Day 20250807, Cycle 3",
      "reward": -395.99917403351475,
      "steps": 300,
      "time_minutes": 4.289486157894134,
      "avg_loss": 0.1979894766708215,
      "epsilon": 0.009995187929535779,
      "vehicles": 349,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 14400
    },
    {
      "episode": 49,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -367.7094858019985,
      "steps": 300,
      "time_minutes": 4.222272038459778,
      "avg_loss": 0.2070529950906833,
      "epsilon": 0.009995187929535779,
      "vehicles": 310,
      "completed_trips": 446,
      "passenger_throughput": 7298.181818181819,
      "memory_size": 14700
    },
    {
      "episode": 50,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -396.1197336185188,
      "steps": 300,
      "time_minutes": 4.314313491185506,
      "avg_loss": 0.20298094188173613,
      "epsilon": 0.009995187929535779,
      "vehicles": 361,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 15000
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -393.07139462719397,
      "reward_std": 27.29687168280574,
      "avg_vehicles": 354.9,
      "avg_completed_trips": 476.7,
      "avg_passenger_throughput": 7800.545454545456,
      "scenarios_tested": 10
    },
    {
      "episode": 30,
      "avg_reward": -384.48897727235067,
      "reward_std": 25.84363391706427,
      "avg_vehicles": 353.7,
      "avg_completed_trips": 481.5,
      "avg_passenger_throughput": 7879.090909090909,
      "scenarios_tested": 10
    },
    {
      "episode": 45,
      "avg_reward": -388.6396647872974,
      "reward_std": 38.340920908972265,
      "avg_vehicles": 351.8,
      "avg_completed_trips": 480.7,
      "avg_passenger_throughput": 7866.0,
      "scenarios_tested": 10
    }
  ],
  "final_evaluation": {
    "test_scenarios": 7,
    "comparison_results": null,
    "evaluation_timestamp": "2025-10-17T10:37:36.878320"
  },
  "logger_summary": {
    "experiment_id": "stability_test_50ep_20251017_064127",
    "session_id": "53288851-6cc1-45f9-8a11-f1e463bcb7ed",
    "timestamp": "2025-10-17T10:37:36.880363",
    "total_episodes": 50,
    "performance_metrics": {
      "avg_reward": -1.2053381556627063,
      "best_reward": -0.7881936070647024,
      "reward_improvement": -3.92449285603564,
      "avg_passenger_throughput": 7938.327272727273,
      "avg_vehicles_served": 485.12,
      "avg_pt_throughput": 2908.32
    },
    "learning_metrics": {
      "convergence_episode": -1,
      "stability_score": 0.8661476248499265,
      "exploration_rate": 1.242671082562911
    },
    "config": {
      "log_interval": 30,
      "buffer_size": 100,
      "total_steps": 14950
    }
  },
  "defense_ready": true,
  "timestamp": "2025-10-17T10:37:36.881344"
}