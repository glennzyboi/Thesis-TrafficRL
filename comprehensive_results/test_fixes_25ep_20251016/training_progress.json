{
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -403.13137621989995,
      "steps": 300,
      "time_minutes": 3.208618112405141,
      "avg_loss": 0.1090283490464849,
      "epsilon": 0.8886698277259029,
      "vehicles": 361,
      "completed_trips": 486,
      "passenger_throughput": 7952.727272727273,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -400.4549467091024,
      "steps": 300,
      "time_minutes": 3.5348651885986326,
      "avg_loss": 0.06944758350650469,
      "epsilon": 0.764856516910148,
      "vehicles": 350,
      "completed_trips": 491,
      "passenger_throughput": 8034.545454545455,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -326.42375670955386,
      "steps": 300,
      "time_minutes": 3.56196368932724,
      "avg_loss": 0.05344415809959173,
      "epsilon": 0.658293410227447,
      "vehicles": 376,
      "completed_trips": 515,
      "passenger_throughput": 8427.272727272728,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -304.2404361599586,
      "steps": 300,
      "time_minutes": 3.5941787481307985,
      "avg_loss": 0.04398210996761918,
      "epsilon": 0.5665771348847519,
      "vehicles": 354,
      "completed_trips": 524,
      "passenger_throughput": 8574.545454545456,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -310.67773223343283,
      "steps": 300,
      "time_minutes": 3.622389256954193,
      "avg_loss": 0.04029756907373667,
      "epsilon": 0.4876391663457515,
      "vehicles": 315,
      "completed_trips": 470,
      "passenger_throughput": 7690.909090909092,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -411.7649225552697,
      "steps": 300,
      "time_minutes": 3.6428834478060406,
      "avg_loss": 0.039481374559303124,
      "epsilon": 0.4196991758284578,
      "vehicles": 360,
      "completed_trips": 473,
      "passenger_throughput": 7740.000000000001,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -387.53459552897766,
      "steps": 300,
      "time_minutes": 3.658460962772369,
      "avg_loss": 0.0370683188115557,
      "epsilon": 0.3612248776305073,
      "vehicles": 349,
      "completed_trips": 482,
      "passenger_throughput": 7887.272727272728,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -279.72007855037316,
      "steps": 300,
      "time_minutes": 3.6829821745554607,
      "avg_loss": 0.036501357971380155,
      "epsilon": 0.31089747069817225,
      "vehicles": 361,
      "completed_trips": 476,
      "passenger_throughput": 7789.09090909091,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -422.1025184377637,
      "steps": 300,
      "time_minutes": 3.6945481379826863,
      "avg_loss": 0.033275545394668975,
      "epsilon": 0.2675818950249339,
      "vehicles": 352,
      "completed_trips": 480,
      "passenger_throughput": 7854.545454545455,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -354.15562844691874,
      "steps": 300,
      "time_minutes": 3.7269163409868877,
      "avg_loss": 0.031544565272827944,
      "epsilon": 0.23030123205680855,
      "vehicles": 355,
      "completed_trips": 490,
      "passenger_throughput": 8018.181818181819,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -416.56938704370594,
      "steps": 300,
      "time_minutes": 3.7586232304573057,
      "avg_loss": 0.07655188769102096,
      "epsilon": 0.19821467174354895,
      "vehicles": 355,
      "completed_trips": 497,
      "passenger_throughput": 8132.727272727273,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -380.06007879674314,
      "steps": 300,
      "time_minutes": 3.750814727942149,
      "avg_loss": 0.0709778460363547,
      "epsilon": 0.17059854931523513,
      "vehicles": 355,
      "completed_trips": 484,
      "passenger_throughput": 7920.000000000001,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -235.483343181716,
      "steps": 300,
      "time_minutes": 3.7565003355344135,
      "avg_loss": 0.06769170267507434,
      "epsilon": 0.14683002409689105,
      "vehicles": 310,
      "completed_trips": 449,
      "passenger_throughput": 7347.272727272728,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -418.7497162396694,
      "steps": 300,
      "time_minutes": 3.7945170362790424,
      "avg_loss": 0.0642028517400225,
      "epsilon": 0.12637303226099805,
      "vehicles": 422,
      "completed_trips": 491,
      "passenger_throughput": 8034.545454545455,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -269.22866618507055,
      "steps": 300,
      "time_minutes": 3.7794009327888487,
      "avg_loss": 0.06155648812030753,
      "epsilon": 0.1087661967030719,
      "vehicles": 325,
      "completed_trips": 477,
      "passenger_throughput": 7805.454545454546,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -333.3612166418084,
      "steps": 300,
      "time_minutes": 3.7601343353589374,
      "avg_loss": 0.05891166217625141,
      "epsilon": 0.09361242136549094,
      "vehicles": 321,
      "completed_trips": 475,
      "passenger_throughput": 7772.727272727273,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -359.1019175722496,
      "steps": 300,
      "time_minutes": 3.78184654712677,
      "avg_loss": 0.05839568601921201,
      "epsilon": 0.08056993532497697,
      "vehicles": 351,
      "completed_trips": 506,
      "passenger_throughput": 8280.0,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -300.33434138911224,
      "steps": 300,
      "time_minutes": 3.775043487548828,
      "avg_loss": 0.05391016298905015,
      "epsilon": 0.07587745223544981,
      "vehicles": 330,
      "completed_trips": 514,
      "passenger_throughput": 8410.909090909092,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -372.8230802487739,
      "steps": 300,
      "time_minutes": 3.7750184377034506,
      "avg_loss": 0.05101273053636154,
      "epsilon": 0.07145826460603061,
      "vehicles": 333,
      "completed_trips": 459,
      "passenger_throughput": 7510.909090909091,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -376.28273194195884,
      "steps": 300,
      "time_minutes": 3.797572640577952,
      "avg_loss": 0.04997696214665969,
      "epsilon": 0.06729645540364951,
      "vehicles": 376,
      "completed_trips": 514,
      "passenger_throughput": 8410.909090909092,
      "memory_size": 6000
    },
    {
      "episode": 21,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -351.47509169565154,
      "steps": 300,
      "time_minutes": 3.787853137652079,
      "avg_loss": 0.0885807104036212,
      "epsilon": 0.06337703462103352,
      "vehicles": 340,
      "completed_trips": 491,
      "passenger_throughput": 8034.545454545455,
      "memory_size": 6300
    },
    {
      "episode": 22,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -300.6867036830053,
      "steps": 300,
      "time_minutes": 3.7934242208798725,
      "avg_loss": 0.08322058861454328,
      "epsilon": 0.059685885285688564,
      "vehicles": 358,
      "completed_trips": 504,
      "passenger_throughput": 8247.272727272728,
      "memory_size": 6600
    },
    {
      "episode": 23,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -327.79906062701514,
      "steps": 300,
      "time_minutes": 3.902565554777781,
      "avg_loss": 0.07519523712495962,
      "epsilon": 0.05620971261337755,
      "vehicles": 342,
      "completed_trips": 462,
      "passenger_throughput": 7560.000000000001,
      "memory_size": 6900
    },
    {
      "episode": 24,
      "scenario": "Day 20250709, Cycle 2",
      "reward": -376.3071081057178,
      "steps": 300,
      "time_minutes": 3.8020683328310647,
      "avg_loss": 0.07385985946903627,
      "epsilon": 0.05293599612295752,
      "vehicles": 321,
      "completed_trips": 457,
      "passenger_throughput": 7478.181818181819,
      "memory_size": 7200
    },
    {
      "episode": 25,
      "scenario": "Day 20250708, Cycle 1",
      "reward": -400.7789469693071,
      "steps": 300,
      "time_minutes": 3.792114496231079,
      "avg_loss": 0.07041588496416808,
      "epsilon": 0.04985294454010186,
      "vehicles": 315,
      "completed_trips": 478,
      "passenger_throughput": 7821.818181818182,
      "memory_size": 7500
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -410.4062237613666,
      "reward_std": 37.408641072006525,
      "avg_vehicles": 356.2,
      "avg_completed_trips": 478.4,
      "avg_passenger_throughput": 7828.363636363637,
      "scenarios_tested": 10
    }
  ],
  "last_updated": "2025-10-16T07:50:46.128345"
}