{
  "experiment_name": "stability_test_50ep",
  "config": {
    "experiment_name": "stability_test_50ep",
    "learning_rate": 0.0005,
    "epsilon_decay": 0.9995,
    "memory_size": 50000,
    "batch_size": 128,
    "gamma": 0.98,
    "sequence_length": 10,
    "episodes": 50,
    "target_update_freq": 10,
    "save_freq": 25,
    "validation_freq": 15,
    "episode_duration": 300,
    "warmup_time": 30,
    "min_phase_time": 12,
    "max_phase_time": 120,
    "random_seed": 42,
    "validation_episodes": 10,
    "agent_type": "lstm",
    "offline_episodes": 35,
    "online_episodes": 15
  },
  "training_time_minutes": 236.01947324275972,
  "best_reward": -260.42286041742204,
  "convergence_episode": -1,
  "training_results": [
    {
      "episode": 1,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -417.2075718484685,
      "steps": 300,
      "time_minutes": 2.7897018353144327,
      "avg_loss": 0.10900850910260233,
      "epsilon": 0.917574496577849,
      "vehicles": 445,
      "completed_trips": 612,
      "passenger_throughput": 10353.28502247809,
      "memory_size": 300
    },
    {
      "episode": 2,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -330.31053012368574,
      "steps": 300,
      "time_minutes": 4.164105594158173,
      "avg_loss": 0.0617547074953715,
      "epsilon": 0.7897340627103864,
      "vehicles": 426,
      "completed_trips": 631,
      "passenger_throughput": 10695.05731646203,
      "memory_size": 600
    },
    {
      "episode": 3,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -401.79877632539365,
      "steps": 300,
      "time_minutes": 4.208206478754679,
      "avg_loss": 0.04819875678668419,
      "epsilon": 0.6797049091175745,
      "vehicles": 456,
      "completed_trips": 675,
      "passenger_throughput": 11090.688780351957,
      "memory_size": 900
    },
    {
      "episode": 4,
      "scenario": "Day 20250717, Cycle 2",
      "reward": -317.18341574478666,
      "steps": 300,
      "time_minutes": 4.226705547173818,
      "avg_loss": 0.042131574352582295,
      "epsilon": 0.5850054914599224,
      "vehicles": 440,
      "completed_trips": 645,
      "passenger_throughput": 10439.065143816772,
      "memory_size": 1200
    },
    {
      "episode": 5,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -320.99671262462596,
      "steps": 300,
      "time_minutes": 4.237200633684794,
      "avg_loss": 0.03526157223929961,
      "epsilon": 0.5035000048514676,
      "vehicles": 391,
      "completed_trips": 593,
      "passenger_throughput": 9411.61408419375,
      "memory_size": 1500
    },
    {
      "episode": 6,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -356.99665919020566,
      "steps": 300,
      "time_minutes": 4.276333391666412,
      "avg_loss": 0.0322244304480652,
      "epsilon": 0.43335021394888135,
      "vehicles": 413,
      "completed_trips": 600,
      "passenger_throughput": 9974.067761865603,
      "memory_size": 1800
    },
    {
      "episode": 7,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -313.63246762895665,
      "steps": 300,
      "time_minutes": 4.304036017258962,
      "avg_loss": 0.029117244991163412,
      "epsilon": 0.37297399428017836,
      "vehicles": 447,
      "completed_trips": 593,
      "passenger_throughput": 9458.262437389469,
      "memory_size": 2100
    },
    {
      "episode": 8,
      "scenario": "Day 20250811, Cycle 2",
      "reward": -397.40548273860963,
      "steps": 300,
      "time_minutes": 4.327144972483317,
      "avg_loss": 0.026599112258603175,
      "epsilon": 0.32100964977421276,
      "vehicles": 441,
      "completed_trips": 618,
      "passenger_throughput": 9339.9928010902,
      "memory_size": 2400
    },
    {
      "episode": 9,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -404.70777708622927,
      "steps": 300,
      "time_minutes": 4.357391719023386,
      "avg_loss": 0.02622652304979662,
      "epsilon": 0.27628520172576376,
      "vehicles": 442,
      "completed_trips": 597,
      "passenger_throughput": 9799.936141051485,
      "memory_size": 2700
    },
    {
      "episode": 10,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -313.95177378178835,
      "steps": 300,
      "time_minutes": 4.374318738778432,
      "avg_loss": 0.02554453625033299,
      "epsilon": 0.2377919565543782,
      "vehicles": 432,
      "completed_trips": 615,
      "passenger_throughput": 9697.179370332633,
      "memory_size": 3000
    },
    {
      "episode": 11,
      "scenario": "Day 20250703, Cycle 1",
      "reward": -327.2248471866941,
      "steps": 300,
      "time_minutes": 4.4049143354098,
      "avg_loss": 0.06570272504041592,
      "epsilon": 0.20466175621698698,
      "vehicles": 453,
      "completed_trips": 641,
      "passenger_throughput": 10029.868476842115,
      "memory_size": 3300
    },
    {
      "episode": 12,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -390.11025558748366,
      "steps": 300,
      "time_minutes": 4.415912004311879,
      "avg_loss": 0.05750501733894149,
      "epsilon": 0.1761473981910859,
      "vehicles": 430,
      "completed_trips": 623,
      "passenger_throughput": 10163.634375618343,
      "memory_size": 3600
    },
    {
      "episode": 13,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -331.91254549218996,
      "steps": 300,
      "time_minutes": 4.401477018992106,
      "avg_loss": 0.0531120854926606,
      "epsilon": 0.15160578343025852,
      "vehicles": 385,
      "completed_trips": 558,
      "passenger_throughput": 9140.462021299894,
      "memory_size": 3900
    },
    {
      "episode": 14,
      "scenario": "Day 20250715, Cycle 1",
      "reward": -412.53745799807507,
      "steps": 300,
      "time_minutes": 4.457914205392202,
      "avg_loss": 0.0521415495313704,
      "epsilon": 0.13048341221917423,
      "vehicles": 483,
      "completed_trips": 631,
      "passenger_throughput": 9601.791037856006,
      "memory_size": 4200
    },
    {
      "episode": 15,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -346.00377807624795,
      "steps": 300,
      "time_minutes": 4.4229648351669315,
      "avg_loss": 0.05008695056661963,
      "epsilon": 0.11230390080858102,
      "vehicles": 417,
      "completed_trips": 587,
      "passenger_throughput": 9387.619531986573,
      "memory_size": 4500
    },
    {
      "episode": 16,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -318.2869085321035,
      "steps": 300,
      "time_minutes": 4.379205624262492,
      "avg_loss": 0.05086731219043334,
      "epsilon": 0.09665723728652038,
      "vehicles": 390,
      "completed_trips": 591,
      "passenger_throughput": 9035.418983661135,
      "memory_size": 4800
    },
    {
      "episode": 17,
      "scenario": "Day 20250716, Cycle 1",
      "reward": -423.3080618512041,
      "steps": 300,
      "time_minutes": 4.418512682120006,
      "avg_loss": 0.04655821692198515,
      "epsilon": 0.08319053436787543,
      "vehicles": 446,
      "completed_trips": 620,
      "passenger_throughput": 9373.847115558257,
      "memory_size": 5100
    },
    {
      "episode": 18,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -260.42286041742204,
      "steps": 300,
      "time_minutes": 4.408346597353617,
      "avg_loss": 0.04314780843754609,
      "epsilon": 0.07160007054513429,
      "vehicles": 398,
      "completed_trips": 660,
      "passenger_throughput": 11048.600266430441,
      "memory_size": 5400
    },
    {
      "episode": 19,
      "scenario": "Day 20250717, Cycle 3",
      "reward": -358.48490161287197,
      "steps": 300,
      "time_minutes": 4.424703598022461,
      "avg_loss": 0.041898553843299546,
      "epsilon": 0.0616244401003375,
      "vehicles": 442,
      "completed_trips": 633,
      "passenger_throughput": 9692.359501335892,
      "memory_size": 5700
    },
    {
      "episode": 20,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -425.3661852104741,
      "steps": 300,
      "time_minutes": 4.413446350892385,
      "avg_loss": 0.04136093247060974,
      "epsilon": 0.05303865748688375,
      "vehicles": 446,
      "completed_trips": 596,
      "passenger_throughput": 10178.30118282256,
      "memory_size": 6000
    },
    {
      "episode": 21,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -427.23597839684174,
      "steps": 300,
      "time_minutes": 4.4219913204511005,
      "avg_loss": 0.08425436151524385,
      "epsilon": 0.045649083114274965,
      "vehicles": 412,
      "completed_trips": 582,
      "passenger_throughput": 10531.664595729715,
      "memory_size": 6300
    },
    {
      "episode": 22,
      "scenario": "Day 20250715, Cycle 2",
      "reward": -343.5191312750031,
      "steps": 300,
      "time_minutes": 4.422844632466634,
      "avg_loss": 0.07775943464289109,
      "epsilon": 0.03928905609440261,
      "vehicles": 393,
      "completed_trips": 586,
      "passenger_throughput": 9641.769647059651,
      "memory_size": 6600
    },
    {
      "episode": 23,
      "scenario": "Day 20250716, Cycle 3",
      "reward": -386.35469115291943,
      "steps": 300,
      "time_minutes": 4.445439279079437,
      "avg_loss": 0.07629287652671338,
      "epsilon": 0.03381513545244477,
      "vehicles": 463,
      "completed_trips": 620,
      "passenger_throughput": 10093.730855857691,
      "memory_size": 6900
    },
    {
      "episode": 24,
      "scenario": "Day 20250707, Cycle 3",
      "reward": -289.9587022622221,
      "steps": 300,
      "time_minutes": 4.420602770646413,
      "avg_loss": 0.0712075966099898,
      "epsilon": 0.029103865028462517,
      "vehicles": 386,
      "completed_trips": 596,
      "passenger_throughput": 9939.594423575347,
      "memory_size": 7200
    },
    {
      "episode": 25,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -434.9850209169369,
      "steps": 300,
      "time_minutes": 4.442452649275462,
      "avg_loss": 0.06824454306314388,
      "epsilon": 0.02504898910685048,
      "vehicles": 436,
      "completed_trips": 615,
      "passenger_throughput": 10903.297558142347,
      "memory_size": 7500
    },
    {
      "episode": 26,
      "scenario": "Day 20250811, Cycle 3",
      "reward": -394.4577808316762,
      "steps": 300,
      "time_minutes": 4.472344819704691,
      "avg_loss": 0.06585114856561025,
      "epsilon": 0.021559055976293522,
      "vehicles": 456,
      "completed_trips": 593,
      "passenger_throughput": 10467.776151013088,
      "memory_size": 7800
    },
    {
      "episode": 27,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -304.2608222513187,
      "steps": 300,
      "time_minutes": 4.463093872865041,
      "avg_loss": 0.06794712091485659,
      "epsilon": 0.01855535537207943,
      "vehicles": 396,
      "completed_trips": 596,
      "passenger_throughput": 9945.560802428552,
      "memory_size": 8100
    },
    {
      "episode": 28,
      "scenario": "Day 20250812, Cycle 3",
      "reward": -418.73617864273405,
      "steps": 300,
      "time_minutes": 4.510920254389445,
      "avg_loss": 0.0648800695190827,
      "epsilon": 0.015970143282839144,
      "vehicles": 447,
      "completed_trips": 646,
      "passenger_throughput": 10990.58420783254,
      "memory_size": 8400
    },
    {
      "episode": 29,
      "scenario": "Day 20250703, Cycle 2",
      "reward": -385.5407235379696,
      "steps": 300,
      "time_minutes": 4.50216490427653,
      "avg_loss": 0.062336174386243025,
      "epsilon": 0.013745114084863256,
      "vehicles": 457,
      "completed_trips": 656,
      "passenger_throughput": 11606.636670428386,
      "memory_size": 8700
    },
    {
      "episode": 30,
      "scenario": "Day 20250812, Cycle 2",
      "reward": -352.81903540311794,
      "steps": 300,
      "time_minutes": 4.486030908425649,
      "avg_loss": 0.05951264088352521,
      "epsilon": 0.011830085545251234,
      "vehicles": 387,
      "completed_trips": 605,
      "passenger_throughput": 10177.503734457498,
      "memory_size": 9000
    },
    {
      "episode": 31,
      "scenario": "Day 20250818, Cycle 3",
      "reward": -364.2886231856565,
      "steps": 300,
      "time_minutes": 4.442321733633677,
      "avg_loss": 0.10238262730340163,
      "epsilon": 0.01018186703608976,
      "vehicles": 416,
      "completed_trips": 582,
      "passenger_throughput": 9217.661849544676,
      "memory_size": 9300
    },
    {
      "episode": 32,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -302.23800078568235,
      "steps": 300,
      "time_minutes": 4.443424570560455,
      "avg_loss": 0.09544698933760325,
      "epsilon": 0.009995187929535779,
      "vehicles": 433,
      "completed_trips": 597,
      "passenger_throughput": 10616.470792370903,
      "memory_size": 9600
    },
    {
      "episode": 33,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -337.1225914748949,
      "steps": 300,
      "time_minutes": 4.420101877053579,
      "avg_loss": 0.09377993680536748,
      "epsilon": 0.009995187929535779,
      "vehicles": 388,
      "completed_trips": 568,
      "passenger_throughput": 10522.067758718546,
      "memory_size": 9900
    },
    {
      "episode": 34,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -398.0160819863436,
      "steps": 300,
      "time_minutes": 4.487771860758463,
      "avg_loss": 0.08732367143034934,
      "epsilon": 0.009995187929535779,
      "vehicles": 453,
      "completed_trips": 637,
      "passenger_throughput": 10947.980247941307,
      "memory_size": 10200
    },
    {
      "episode": 35,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -345.41119596302207,
      "steps": 300,
      "time_minutes": 4.464093144734701,
      "avg_loss": 0.08330414281537135,
      "epsilon": 0.009995187929535779,
      "vehicles": 416,
      "completed_trips": 640,
      "passenger_throughput": 10891.040114464327,
      "memory_size": 10500
    },
    {
      "episode": 36,
      "scenario": "Day 20250812, Cycle 1",
      "reward": -401.02539134747116,
      "steps": 300,
      "time_minutes": 4.248310160636902,
      "avg_loss": 0.08620104819536209,
      "epsilon": 0.009995187929535779,
      "vehicles": 456,
      "completed_trips": 648,
      "passenger_throughput": 11520.10373932332,
      "memory_size": 10800
    },
    {
      "episode": 37,
      "scenario": "Day 20250819, Cycle 3",
      "reward": -401.2317428882637,
      "steps": 300,
      "time_minutes": 4.269490746657054,
      "avg_loss": 0.08312950193881989,
      "epsilon": 0.009995187929535779,
      "vehicles": 407,
      "completed_trips": 592,
      "passenger_throughput": 10686.035958056333,
      "memory_size": 11100
    },
    {
      "episode": 38,
      "scenario": "Day 20250701, Cycle 1",
      "reward": -403.2341714585463,
      "steps": 300,
      "time_minutes": 4.27857863108317,
      "avg_loss": 0.07803191155195237,
      "epsilon": 0.009995187929535779,
      "vehicles": 492,
      "completed_trips": 622,
      "passenger_throughput": 10684.169059637268,
      "memory_size": 11400
    },
    {
      "episode": 39,
      "scenario": "Day 20250811, Cycle 1",
      "reward": -375.1486871563684,
      "steps": 300,
      "time_minutes": 4.241923530896504,
      "avg_loss": 0.0722855091529588,
      "epsilon": 0.009995187929535779,
      "vehicles": 421,
      "completed_trips": 630,
      "passenger_throughput": 10866.979633021549,
      "memory_size": 11700
    },
    {
      "episode": 40,
      "scenario": "Day 20250703, Cycle 3",
      "reward": -338.14377972639977,
      "steps": 300,
      "time_minutes": 4.258726076285044,
      "avg_loss": 0.07556731304774682,
      "epsilon": 0.009995187929535779,
      "vehicles": 427,
      "completed_trips": 642,
      "passenger_throughput": 12616.363636363638,
      "memory_size": 12000
    },
    {
      "episode": 41,
      "scenario": "Day 20250821, Cycle 1",
      "reward": -368.19071319225066,
      "steps": 300,
      "time_minutes": 4.244262965520223,
      "avg_loss": 0.10900588937103749,
      "epsilon": 0.009995187929535779,
      "vehicles": 425,
      "completed_trips": 627,
      "passenger_throughput": 10187.54275364106,
      "memory_size": 12300
    },
    {
      "episode": 42,
      "scenario": "Day 20250709, Cycle 2",
      "reward": -409.82878414177475,
      "steps": 300,
      "time_minutes": 4.225959018866221,
      "avg_loss": 0.10932425564775865,
      "epsilon": 0.009995187929535779,
      "vehicles": 402,
      "completed_trips": 575,
      "passenger_throughput": 10685.254931393258,
      "memory_size": 12600
    },
    {
      "episode": 43,
      "scenario": "Day 20250708, Cycle 1",
      "reward": -396.478900768827,
      "steps": 300,
      "time_minutes": 4.246899060408274,
      "avg_loss": 0.10394851210216681,
      "epsilon": 0.009995187929535779,
      "vehicles": 402,
      "completed_trips": 591,
      "passenger_throughput": 10125.307773536617,
      "memory_size": 12900
    },
    {
      "episode": 44,
      "scenario": "Day 20250821, Cycle 3",
      "reward": -354.10048844482964,
      "steps": 300,
      "time_minutes": 4.27143536011378,
      "avg_loss": 0.10551731836050748,
      "epsilon": 0.009995187929535779,
      "vehicles": 440,
      "completed_trips": 590,
      "passenger_throughput": 10632.481780041473,
      "memory_size": 13200
    },
    {
      "episode": 45,
      "scenario": "Day 20250717, Cycle 1",
      "reward": -371.5640113379219,
      "steps": 300,
      "time_minutes": 4.26942732334137,
      "avg_loss": 0.09207904040813446,
      "epsilon": 0.009995187929535779,
      "vehicles": 456,
      "completed_trips": 603,
      "passenger_throughput": 10833.127370548616,
      "memory_size": 13500
    },
    {
      "episode": 46,
      "scenario": "Day 20250804, Cycle 1",
      "reward": -386.26802157304536,
      "steps": 300,
      "time_minutes": 4.283333110809326,
      "avg_loss": 0.09130170969913404,
      "epsilon": 0.009995187929535779,
      "vehicles": 437,
      "completed_trips": 598,
      "passenger_throughput": 10757.332137174755,
      "memory_size": 13800
    },
    {
      "episode": 47,
      "scenario": "Day 20250707, Cycle 1",
      "reward": -382.5109241118318,
      "steps": 300,
      "time_minutes": 4.298646871248881,
      "avg_loss": 0.08916833924750488,
      "epsilon": 0.009995187929535779,
      "vehicles": 437,
      "completed_trips": 608,
      "passenger_throughput": 11377.548302857687,
      "memory_size": 14100
    },
    {
      "episode": 48,
      "scenario": "Day 20250807, Cycle 3",
      "reward": -394.656373740669,
      "steps": 300,
      "time_minutes": 4.327912557125091,
      "avg_loss": 0.09207620941102505,
      "epsilon": 0.009995187929535779,
      "vehicles": 440,
      "completed_trips": 600,
      "passenger_throughput": 11248.340704771772,
      "memory_size": 14400
    },
    {
      "episode": 49,
      "scenario": "Day 20250708, Cycle 2",
      "reward": -404.0297682829543,
      "steps": 300,
      "time_minutes": 4.298629136880239,
      "avg_loss": 0.08863196925570567,
      "epsilon": 0.009995187929535779,
      "vehicles": 401,
      "completed_trips": 545,
      "passenger_throughput": 10183.403969601834,
      "memory_size": 14700
    },
    {
      "episode": 50,
      "scenario": "Day 20250804, Cycle 2",
      "reward": -433.64205302760365,
      "steps": 300,
      "time_minutes": 4.326618603865305,
      "avg_loss": 0.09174718845635653,
      "epsilon": 0.009995187929535779,
      "vehicles": 446,
      "completed_trips": 591,
      "passenger_throughput": 11037.631360495361,
      "memory_size": 15000
    }
  ],
  "validation_results": [
    {
      "episode": 15,
      "avg_reward": -403.53204052150903,
      "reward_std": 27.438742513819598,
      "avg_vehicles": 353.1,
      "avg_completed_trips": 481.1,
      "avg_passenger_throughput": 7872.545454545456,
      "scenarios_tested": 10
    },
    {
      "episode": 30,
      "avg_reward": -363.0167730096275,
      "reward_std": 41.88330269341835,
      "avg_vehicles": 355.8,
      "avg_completed_trips": 480.6,
      "avg_passenger_throughput": 7864.363636363638,
      "scenarios_tested": 10
    },
    {
      "episode": 45,
      "avg_reward": -382.6877482526223,
      "reward_std": 31.25434545779057,
      "avg_vehicles": 351.2,
      "avg_completed_trips": 483.4,
      "avg_passenger_throughput": 7910.181818181819,
      "scenarios_tested": 10
    }
  ],
  "final_evaluation": {
    "test_scenarios": 7,
    "comparison_results": null,
    "evaluation_timestamp": "2025-10-17T21:18:26.865090"
  },
  "logger_summary": {
    "experiment_id": "stability_test_50ep",
    "session_id": "712733d1-3dba-4531-b7f0-44477115e4f1",
    "timestamp": "2025-10-17T21:18:26.867143",
    "total_episodes": 50,
    "performance_metrics": {
      "avg_reward": -1.2315231558881745,
      "best_reward": -0.8680762013914068,
      "reward_improvement": -11.950237302352214,
      "avg_passenger_throughput": 7990.036363636364,
      "avg_vehicles_served": 488.28,
      "avg_pt_throughput": 2904.8
    },
    "learning_metrics": {
      "convergence_episode": -1,
      "stability_score": 0.8865170813888479,
      "exploration_rate": 1.227394504388616
    },
    "config": {
      "log_interval": 30,
      "buffer_size": 100,
      "total_steps": 14950
    }
  },
  "defense_ready": true,
  "timestamp": "2025-10-17T21:18:26.869134"
}